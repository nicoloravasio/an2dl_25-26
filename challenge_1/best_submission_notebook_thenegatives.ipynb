{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "gPSIfSTkMXPS",
      "metadata": {
        "id": "gPSIfSTkMXPS"
      },
      "source": [
        "# AN2DL [2025–2026] — Time Series Classification (Stratified K-Fold, SMOTE, XGBoost)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da8b8757",
      "metadata": {},
      "source": [
        "**NOTEBOOK BY thenegatives**\n",
        "\n",
        "\n",
        "**Burchini - Collovigh - Corti - Ravasio**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8lIVsqhmMXPU",
      "metadata": {
        "id": "8lIVsqhmMXPU"
      },
      "source": [
        "## Google Drive (opzionale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "oUWqjG2wMXPU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUWqjG2wMXPU",
        "outputId": "d0dc1a4f-a0d3-4719-df80-c5e5b0db306a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "Working dir: /gdrive/My Drive/AN2DL\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/gdrive\")\n",
        "    current_dir = \"/gdrive/My Drive/AN2DL//\"\n",
        "    try:\n",
        "        os.chdir(current_dir)\n",
        "    except FileNotFoundError:\n",
        "        print(\"⚠️ Aggiorna `current_dir` alla tua cartella dati.\")\n",
        "else:\n",
        "    current_dir = \".\"\n",
        "print(\"Working dir:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QQZSYnmdMXPU",
      "metadata": {
        "id": "QQZSYnmdMXPU"
      },
      "source": [
        "## Librerie & seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "92r9KGEEMXPU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92r9KGEEMXPU",
        "outputId": "9d70d91e-c2f0-44d1-a581-202d44a7beb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, random, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SEED = 42\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "set_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BYzCC2nwMXPV",
      "metadata": {
        "id": "BYzCC2nwMXPV"
      },
      "source": [
        "## Configurazione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "F1Vq1-r4MXPV",
      "metadata": {
        "id": "F1Vq1-r4MXPV"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    n_folds = 10\n",
        "    epochs = 65\n",
        "    batch_size = 128\n",
        "    lr = 5e-4\n",
        "    weight_decay = 1e-4\n",
        "    max_grad_norm = 2.0\n",
        "    patience = 10\n",
        "    label_smoothing = 0.01\n",
        "    use_weighted_sampler = False\n",
        "\n",
        "    hidden1 = 256\n",
        "    hidden2 = 128\n",
        "    dropout = 0.20\n",
        "\n",
        "    train_csv = \"pirate_pain_train.csv\"\n",
        "    train_labels_csv = \"pirate_pain_train_labels.csv\"\n",
        "    test_csv = \"pirate_pain_test.csv\"\n",
        "\n",
        "cfg = CFG()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vla5r_MFMXPV",
      "metadata": {
        "id": "vla5r_MFMXPV"
      },
      "source": [
        "## Caricamento dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "MZcTy0XAMXPV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZcTy0XAMXPV",
        "outputId": "c733b89a-d83e-434b-85a9-63fd7a6909a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train (time-step): (105760, 41) | Test (time-step): (211840, 40)\n",
            "Colonne: ['sample_index', 'time', 'pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4', 'n_legs', 'n_hands', 'n_eyes', 'joint_00'] ...\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(cfg.train_csv)\n",
        "labels_df = pd.read_csv(cfg.train_labels_csv)\n",
        "test_df  = pd.read_csv(cfg.test_csv)\n",
        "\n",
        "data = pd.merge(train_df, labels_df, on=\"sample_index\", how=\"left\")\n",
        "\n",
        "print(\"Train (time-step):\", data.shape, \"| Test (time-step):\", test_df.shape)\n",
        "print(\"Colonne:\", list(data.columns)[:10], \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32fVv0cBMXPW",
      "metadata": {
        "id": "32fVv0cBMXPW"
      },
      "source": [
        "## Selezione feature (35 input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "SAENpgSUMXPW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAENpgSUMXPW",
        "outputId": "2ebb0903-95b9-4e9b-ac51-9c9141ec5bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numero feature: 35\n",
            "Esempio: ['pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4', 'joint_00', 'joint_01', 'joint_02', 'joint_03']\n"
          ]
        }
      ],
      "source": [
        "drop_cols = [\"time\", \"n_legs\", \"n_hands\", \"n_eyes\"]\n",
        "feature_cols = [c for c in data.columns if c not in ([\"sample_index\",\"label\"] + drop_cols)]\n",
        "assert len(feature_cols) == 35, f\"Attese 35 feature, trovate {len(feature_cols)}\"\n",
        "\n",
        "print(\"Numero feature:\", len(feature_cols))\n",
        "print(\"Esempio:\", feature_cols[:8])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J1ZSkI7sMXPX",
      "metadata": {
        "id": "J1ZSkI7sMXPX"
      },
      "source": [
        "## Encoding etichette e tabella sequenze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "FPUaBNxHMXPX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPUaBNxHMXPX",
        "outputId": "4a47bea6-307c-4fd5-eac2-d60790e4b10e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soggetti: 661\n",
            "label_encoded\n",
            "0    511\n",
            "1     94\n",
            "2     56\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "label_encoder = {\"no_pain\":0, \"low_pain\":1, \"high_pain\":2}\n",
        "inv_label_encoder = {v:k for k,v in label_encoder.items()}\n",
        "data[\"label_encoded\"] = data[\"label\"].map(label_encoder).astype(int)\n",
        "\n",
        "seq_df = data[[\"sample_index\",\"label_encoded\"]].drop_duplicates().reset_index(drop=True)\n",
        "print(\"Soggetti:\", len(seq_df))\n",
        "print(seq_df[\"label_encoded\"].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zSSYPiaBMXPX",
      "metadata": {
        "id": "zSSYPiaBMXPX"
      },
      "source": [
        "## Helper: scaler, dataset, modello (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "cvx9Ej0cMXPX",
      "metadata": {
        "id": "cvx9Ej0cMXPX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "def fit_minmax(X):\n",
        "    mn = X.min(axis=0)\n",
        "    mx = X.max(axis=0)\n",
        "    denom = mx - mn\n",
        "    denom = np.where(denom == 0.0, 1.0, denom)\n",
        "    return mn, denom\n",
        "\n",
        "def apply_minmax(X, mn, denom):\n",
        "    return (X - mn) / denom\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, in_dim=35, h1=128, h2=64, out_dim=3, dropout=0.10):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, h1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(h1, h2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(h2, out_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def make_loader(X, y=None, batch_size=256, shuffle=False, sampler=None):\n",
        "    if y is None:\n",
        "        ds = TensorDataset(torch.from_numpy(X.astype(np.float32)))\n",
        "    else:\n",
        "        ds = TensorDataset(torch.from_numpy(X.astype(np.float32)),\n",
        "                           torch.from_numpy(y.astype(np.int64)))\n",
        "    return DataLoader(ds, batch_size=batch_size, shuffle=(sampler is None and shuffle),\n",
        "                      sampler=sampler, num_workers=2, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "noyWvsrAMXPX",
      "metadata": {
        "id": "noyWvsrAMXPX"
      },
      "source": [
        "## Train & Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LkhCdq28MXPX",
      "metadata": {
        "id": "LkhCdq28MXPX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "import torch\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, scaler=None, max_grad_norm=2.0):\n",
        "    model.train()\n",
        "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device); y = y.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast(enabled=(scaler is not None)):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            if max_grad_norm is not None:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if max_grad_norm is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        total_correct += (logits.argmax(1) == y).sum().item()\n",
        "        total_samples += x.size(0)\n",
        "    return total_loss/max(1,total_samples), total_correct/max(1,total_samples)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion=None):\n",
        "    model.eval()\n",
        "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
        "    all_preds, all_tgts = [], []\n",
        "    for x, y in loader:\n",
        "        x = x.to(device); y = y.to(device)\n",
        "        logits = model(x)\n",
        "        if criterion is not None:\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "        total_correct += (logits.argmax(1) == y).sum().item()\n",
        "        total_samples += x.size(0)\n",
        "        all_preds.append(logits.argmax(1).cpu().numpy())\n",
        "        all_tgts.append(y.cpu().numpy())\n",
        "    avg_loss = total_loss/max(1,total_samples) if total_samples>0 else None\n",
        "    acc = total_correct/max(1,total_samples) if total_samples>0 else None\n",
        "    return avg_loss, acc, np.concatenate(all_preds), np.concatenate(all_tgts)\n",
        "\n",
        "\n",
        "def _get_x_from_batch(batch):\n",
        "    # needed as batch may be a tensor, (x,), (x,y) or a dict\n",
        "    if isinstance(batch, (list, tuple)):\n",
        "        x = batch[0]\n",
        "    elif isinstance(batch, dict):\n",
        "        # try common keys\n",
        "        for k in ('x', 'inputs', 'features'):\n",
        "            if k in batch:\n",
        "                x = batch[k]\n",
        "                break\n",
        "        else:\n",
        "            raise ValueError(\"Impossibile estrarre le feature dal batch di tipo dict.\")\n",
        "    else:\n",
        "        x = batch\n",
        "    return x\n",
        "@torch.no_grad()\n",
        "def predict_proba(model, loader):\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            x = _get_x_from_batch(batch)\n",
        "            x = x.to(device, non_blocking=True)  # uses previously defined variable \"device\"\n",
        "            logits = model(x)\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            all_probs.append(probs.detach().cpu().numpy())\n",
        "    return np.concatenate(all_probs, axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_IuhYBOqMXPX",
      "metadata": {
        "id": "_IuhYBOqMXPX"
      },
      "source": [
        "## Stratified K-Fold (group-by `sample_index`) + OOF + XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "2954995c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2954995c",
        "outputId": "c039d406-91b3-445b-9174-f874727b33f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Fold data initialization complete.\n"
          ]
        }
      ],
      "source": [
        "X_all = data[feature_cols].values\n",
        "y_all = data[\"label_encoded\"].values\n",
        "sid_all = data[\"sample_index\"].values\n",
        "X_test_all = test_df[feature_cols].values\n",
        "sid_test_all = test_df[\"sample_index\"].values\n",
        "\n",
        "unique_sids = seq_df[\"sample_index\"].values\n",
        "sid_to_label = dict(zip(seq_df[\"sample_index\"].values, seq_df[\"label_encoded\"].values))\n",
        "y_seq = np.array([sid_to_label[s] for s in unique_sids])\n",
        "\n",
        "print(\"K-Fold data initialization complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e6f5a00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e6f5a00",
        "outputId": "d18bafbd-25da-4dcb-e0f6-4f83be50654a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost setup complete and ensemble weights defined.\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Ensemble weights\n",
        "ENSEMBLE_WEIGHT_NN = 0.5\n",
        "ENSEMBLE_WEIGHT_XGB = 0.5\n",
        "\n",
        "def train_xgb(X_tr, y_tr, X_va, y_va, random_state=SEED):\n",
        "    model_xgb = XGBClassifier(\n",
        "        objective='multi:softprob',  # For multi-class classification with probabilities\n",
        "        num_class=3,                 # Number of classes\n",
        "        eval_metric='mlogloss',      # LogLoss for multi-class\n",
        "        use_label_encoder=False,     # Suppress warning\n",
        "        random_state=random_state,\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=5,\n",
        "        subsample=0.7,\n",
        "        colsample_bytree=0.7,\n",
        "        gamma=0.1,\n",
        "        tree_method='hist', # Faster for larger datasets\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    model_xgb.fit(X_tr, y_tr,\n",
        "                  eval_set=[(X_va, y_va)],\n",
        "                  verbose=False)\n",
        "    return model_xgb\n",
        "\n",
        "# Initialize OOF and test probability arrays for XGBoost\n",
        "oof_probs_xgb = np.zeros((len(X_all), 3), dtype=np.float32)\n",
        "test_fold_probs_xgb = []\n",
        "\n",
        "print(\"XGBoost setup complete and ensemble weights defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75a4dbae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75a4dbae",
        "outputId": "131a3d06-dd0a-4e74-ff52-6ab96431fce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== FOLD 1/10 — XGBoost Training ====\n",
            "XGBoost F1 micro on validation: 0.9198\n",
            "\n",
            "===== FOLD 1/10 — NN Training — train rows: 160480, val rows: 10720 ====\n",
            "Epoch 01 | loss_tr 0.7233 acc_tr 0.7016 | loss_va 0.7505 acc_va 0.7398 | f1_va 0.7398\n",
            "Epoch 02 | loss_tr 0.4610 acc_tr 0.8407 | loss_va 0.6090 acc_va 0.7938 | f1_va 0.7938\n",
            "Epoch 03 | loss_tr 0.3644 acc_tr 0.8843 | loss_va 0.4920 acc_va 0.8609 | f1_va 0.8609\n",
            "Epoch 04 | loss_tr 0.3112 acc_tr 0.9088 | loss_va 0.4960 acc_va 0.8590 | f1_va 0.8590\n",
            "Epoch 05 | loss_tr 0.2777 acc_tr 0.9232 | loss_va 0.5221 acc_va 0.8350 | f1_va 0.8350\n",
            "Epoch 06 | loss_tr 0.2531 acc_tr 0.9336 | loss_va 0.4546 acc_va 0.8744 | f1_va 0.8744\n",
            "Epoch 07 | loss_tr 0.2348 acc_tr 0.9410 | loss_va 0.4899 acc_va 0.8599 | f1_va 0.8599\n",
            "Epoch 08 | loss_tr 0.2208 acc_tr 0.9473 | loss_va 0.4321 acc_va 0.8992 | f1_va 0.8992\n",
            "Epoch 09 | loss_tr 0.2101 acc_tr 0.9516 | loss_va 0.4359 acc_va 0.8777 | f1_va 0.8777\n",
            "Epoch 10 | loss_tr 0.2012 acc_tr 0.9549 | loss_va 0.4044 acc_va 0.9032 | f1_va 0.9032\n",
            "Epoch 11 | loss_tr 0.1925 acc_tr 0.9578 | loss_va 0.4339 acc_va 0.8862 | f1_va 0.8862\n",
            "Epoch 12 | loss_tr 0.1859 acc_tr 0.9605 | loss_va 0.4028 acc_va 0.9178 | f1_va 0.9178\n",
            "Epoch 13 | loss_tr 0.1802 acc_tr 0.9622 | loss_va 0.3921 acc_va 0.9108 | f1_va 0.9108\n",
            "Epoch 14 | loss_tr 0.1745 acc_tr 0.9643 | loss_va 0.4307 acc_va 0.8997 | f1_va 0.8997\n",
            "Epoch 15 | loss_tr 0.1709 acc_tr 0.9656 | loss_va 0.4119 acc_va 0.8983 | f1_va 0.8983\n",
            "Epoch 16 | loss_tr 0.1674 acc_tr 0.9672 | loss_va 0.4139 acc_va 0.9067 | f1_va 0.9067\n",
            "Epoch 17 | loss_tr 0.1649 acc_tr 0.9684 | loss_va 0.4127 acc_va 0.9063 | f1_va 0.9063\n",
            "Epoch 18 | loss_tr 0.1613 acc_tr 0.9694 | loss_va 0.4361 acc_va 0.9074 | f1_va 0.9074\n",
            "Epoch 19 | loss_tr 0.1576 acc_tr 0.9708 | loss_va 0.3851 acc_va 0.9266 | f1_va 0.9266\n",
            "Epoch 20 | loss_tr 0.1583 acc_tr 0.9707 | loss_va 0.4544 acc_va 0.8953 | f1_va 0.8953\n",
            "Epoch 21 | loss_tr 0.1545 acc_tr 0.9721 | loss_va 0.4062 acc_va 0.9048 | f1_va 0.9048\n",
            "Epoch 22 | loss_tr 0.1535 acc_tr 0.9723 | loss_va 0.3939 acc_va 0.9192 | f1_va 0.9192\n",
            "Epoch 23 | loss_tr 0.1512 acc_tr 0.9735 | loss_va 0.4013 acc_va 0.9223 | f1_va 0.9223\n",
            "Epoch 24 | loss_tr 0.1494 acc_tr 0.9741 | loss_va 0.4450 acc_va 0.9054 | f1_va 0.9054\n",
            "Epoch 25 | loss_tr 0.1485 acc_tr 0.9741 | loss_va 0.4127 acc_va 0.9201 | f1_va 0.9201\n",
            "Epoch 26 | loss_tr 0.1472 acc_tr 0.9749 | loss_va 0.4501 acc_va 0.8971 | f1_va 0.8971\n",
            "Epoch 27 | loss_tr 0.1459 acc_tr 0.9756 | loss_va 0.4233 acc_va 0.9148 | f1_va 0.9148\n",
            "Epoch 28 | loss_tr 0.1446 acc_tr 0.9759 | loss_va 0.4133 acc_va 0.9144 | f1_va 0.9144\n",
            "Epoch 29 | loss_tr 0.1437 acc_tr 0.9764 | loss_va 0.4304 acc_va 0.9113 | f1_va 0.9113\n",
            "Early stopping — best F1: 0.9266\n",
            "Fold NN report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     no_pain     0.9644    0.9677    0.9660      8320\n",
            "    low_pain     0.8062    0.9069    0.8536      1440\n",
            "   high_pain     0.7660    0.6000    0.6729       960\n",
            "\n",
            "    accuracy                         0.9266     10720\n",
            "   macro avg     0.8455    0.8249    0.8308     10720\n",
            "weighted avg     0.9254    0.9266    0.9247     10720\n",
            "\n",
            "\n",
            "===== FOLD 2/10 — XGBoost Training ====\n",
            "XGBoost F1 micro on validation: 0.9359\n",
            "\n",
            "===== FOLD 2/10 — NN Training — train rows: 160640, val rows: 10560 ====\n",
            "Epoch 01 | loss_tr 0.7293 acc_tr 0.7040 | loss_va 0.5764 acc_va 0.7886 | f1_va 0.7886\n",
            "Epoch 02 | loss_tr 0.4564 acc_tr 0.8397 | loss_va 0.4576 acc_va 0.8495 | f1_va 0.8495\n",
            "Epoch 03 | loss_tr 0.3584 acc_tr 0.8876 | loss_va 0.3727 acc_va 0.8881 | f1_va 0.8881\n",
            "Epoch 04 | loss_tr 0.3073 acc_tr 0.9110 | loss_va 0.4049 acc_va 0.8735 | f1_va 0.8735\n",
            "Epoch 05 | loss_tr 0.2779 acc_tr 0.9247 | loss_va 0.3600 acc_va 0.9025 | f1_va 0.9025\n",
            "Epoch 06 | loss_tr 0.2548 acc_tr 0.9345 | loss_va 0.3633 acc_va 0.9030 | f1_va 0.9030\n",
            "Epoch 07 | loss_tr 0.2380 acc_tr 0.9406 | loss_va 0.3328 acc_va 0.9168 | f1_va 0.9168\n",
            "Epoch 08 | loss_tr 0.2235 acc_tr 0.9460 | loss_va 0.3345 acc_va 0.9186 | f1_va 0.9186\n",
            "Epoch 09 | loss_tr 0.2122 acc_tr 0.9507 | loss_va 0.3145 acc_va 0.9251 | f1_va 0.9251\n",
            "Epoch 10 | loss_tr 0.2048 acc_tr 0.9537 | loss_va 0.3047 acc_va 0.9297 | f1_va 0.9297\n",
            "Epoch 11 | loss_tr 0.1968 acc_tr 0.9568 | loss_va 0.3125 acc_va 0.9208 | f1_va 0.9208\n",
            "Epoch 12 | loss_tr 0.1887 acc_tr 0.9598 | loss_va 0.3506 acc_va 0.9096 | f1_va 0.9096\n",
            "Epoch 13 | loss_tr 0.1829 acc_tr 0.9612 | loss_va 0.2907 acc_va 0.9334 | f1_va 0.9334\n",
            "Epoch 14 | loss_tr 0.1785 acc_tr 0.9633 | loss_va 0.3207 acc_va 0.9164 | f1_va 0.9164\n",
            "Epoch 15 | loss_tr 0.1742 acc_tr 0.9653 | loss_va 0.3053 acc_va 0.9258 | f1_va 0.9258\n",
            "Epoch 16 | loss_tr 0.1705 acc_tr 0.9666 | loss_va 0.2953 acc_va 0.9277 | f1_va 0.9277\n",
            "Epoch 17 | loss_tr 0.1681 acc_tr 0.9673 | loss_va 0.2815 acc_va 0.9383 | f1_va 0.9383\n",
            "Epoch 18 | loss_tr 0.1637 acc_tr 0.9689 | loss_va 0.2940 acc_va 0.9293 | f1_va 0.9293\n",
            "Epoch 19 | loss_tr 0.1614 acc_tr 0.9695 | loss_va 0.2913 acc_va 0.9331 | f1_va 0.9331\n",
            "Epoch 20 | loss_tr 0.1602 acc_tr 0.9702 | loss_va 0.2952 acc_va 0.9343 | f1_va 0.9343\n",
            "Epoch 21 | loss_tr 0.1573 acc_tr 0.9715 | loss_va 0.2985 acc_va 0.9335 | f1_va 0.9335\n",
            "Epoch 22 | loss_tr 0.1558 acc_tr 0.9721 | loss_va 0.2898 acc_va 0.9325 | f1_va 0.9325\n",
            "Epoch 23 | loss_tr 0.1545 acc_tr 0.9722 | loss_va 0.2815 acc_va 0.9360 | f1_va 0.9360\n",
            "Epoch 24 | loss_tr 0.1527 acc_tr 0.9733 | loss_va 0.2953 acc_va 0.9330 | f1_va 0.9330\n",
            "Epoch 25 | loss_tr 0.1517 acc_tr 0.9736 | loss_va 0.2886 acc_va 0.9330 | f1_va 0.9330\n",
            "Epoch 26 | loss_tr 0.1506 acc_tr 0.9741 | loss_va 0.2826 acc_va 0.9387 | f1_va 0.9387\n",
            "Epoch 27 | loss_tr 0.1492 acc_tr 0.9744 | loss_va 0.3037 acc_va 0.9191 | f1_va 0.9191\n",
            "Epoch 28 | loss_tr 0.1478 acc_tr 0.9753 | loss_va 0.2828 acc_va 0.9389 | f1_va 0.9389\n",
            "Epoch 29 | loss_tr 0.1472 acc_tr 0.9753 | loss_va 0.2599 acc_va 0.9399 | f1_va 0.9399\n",
            "Epoch 30 | loss_tr 0.1466 acc_tr 0.9756 | loss_va 0.2785 acc_va 0.9393 | f1_va 0.9393\n",
            "Epoch 31 | loss_tr 0.1443 acc_tr 0.9766 | loss_va 0.2851 acc_va 0.9405 | f1_va 0.9405\n",
            "Epoch 32 | loss_tr 0.1432 acc_tr 0.9768 | loss_va 0.2718 acc_va 0.9434 | f1_va 0.9434\n",
            "Epoch 33 | loss_tr 0.1421 acc_tr 0.9767 | loss_va 0.2687 acc_va 0.9391 | f1_va 0.9391\n",
            "Epoch 34 | loss_tr 0.1426 acc_tr 0.9770 | loss_va 0.2829 acc_va 0.9332 | f1_va 0.9332\n",
            "Epoch 35 | loss_tr 0.1427 acc_tr 0.9770 | loss_va 0.2844 acc_va 0.9374 | f1_va 0.9374\n",
            "Epoch 36 | loss_tr 0.1399 acc_tr 0.9783 | loss_va 0.2800 acc_va 0.9402 | f1_va 0.9402\n",
            "Epoch 37 | loss_tr 0.1413 acc_tr 0.9773 | loss_va 0.2885 acc_va 0.9365 | f1_va 0.9365\n",
            "Epoch 38 | loss_tr 0.1396 acc_tr 0.9780 | loss_va 0.2822 acc_va 0.9389 | f1_va 0.9389\n",
            "Epoch 39 | loss_tr 0.1390 acc_tr 0.9785 | loss_va 0.2597 acc_va 0.9447 | f1_va 0.9447\n",
            "Epoch 40 | loss_tr 0.1376 acc_tr 0.9787 | loss_va 0.2686 acc_va 0.9445 | f1_va 0.9445\n",
            "Epoch 41 | loss_tr 0.1378 acc_tr 0.9785 | loss_va 0.2687 acc_va 0.9434 | f1_va 0.9434\n",
            "Epoch 42 | loss_tr 0.1371 acc_tr 0.9791 | loss_va 0.2722 acc_va 0.9402 | f1_va 0.9402\n",
            "Epoch 43 | loss_tr 0.1365 acc_tr 0.9794 | loss_va 0.2615 acc_va 0.9448 | f1_va 0.9448\n",
            "Epoch 44 | loss_tr 0.1363 acc_tr 0.9794 | loss_va 0.2587 acc_va 0.9433 | f1_va 0.9433\n",
            "Epoch 45 | loss_tr 0.1357 acc_tr 0.9793 | loss_va 0.2718 acc_va 0.9419 | f1_va 0.9419\n",
            "Epoch 46 | loss_tr 0.1350 acc_tr 0.9797 | loss_va 0.2635 acc_va 0.9432 | f1_va 0.9432\n"
          ]
        }
      ],
      "source": [
        "oof_probs_nn = np.zeros((len(X_all), 3), dtype=np.float32)\n",
        "oof_preds_nn = np.zeros(len(X_all), dtype=np.int64)\n",
        "oof_true   = y_all.copy()\n",
        "test_fold_probs_nn = []\n",
        "\n",
        "models_xgb = [] # To store trained XGBoost models\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "skf = StratifiedKFold(n_splits=cfg.n_folds, shuffle=True, random_state=SEED)\n",
        "for fold, (tr_seq_idx, va_seq_idx) in enumerate(skf.split(unique_sids, y_seq), start=1):\n",
        "    tr_sids = unique_sids[tr_seq_idx]; va_sids = unique_sids[va_seq_idx]\n",
        "    tr_mask = np.isin(sid_all, tr_sids); va_mask = np.isin(sid_all, va_sids)\n",
        "    X_tr, y_tr = X_all[tr_mask], y_all[tr_mask]\n",
        "    X_va, y_va = X_all[va_mask], y_all[va_mask]\n",
        "\n",
        "    # Minority class oversampling is performed with SMOTE\n",
        "    class_counts = np.bincount(y_tr)\n",
        "    if len(class_counts) > 2:\n",
        "        majority_cls = int(np.argmax(class_counts))\n",
        "        minority_cls = 2  # high_pain\n",
        "        if class_counts[minority_cls] < class_counts[majority_cls]:\n",
        "            smote = SMOTE(sampling_strategy={minority_cls: int(class_counts[majority_cls])}, random_state=SEED)\n",
        "            X_tr, y_tr = smote.fit_resample(X_tr, y_tr)\n",
        "\n",
        "    mn, denom = fit_minmax(X_tr)\n",
        "    X_tr_s = apply_minmax(X_tr, mn, denom)\n",
        "    X_va_s = apply_minmax(X_va, mn, denom)\n",
        "    X_te_s = apply_minmax(X_test_all, mn, denom)\n",
        "\n",
        "    # Train and predict with XGBoost\n",
        "    print(f\"\\n===== FOLD {fold}/{cfg.n_folds} \\u2014 XGBoost Training ====\")\n",
        "    xgb_model = train_xgb(X_tr_s, y_tr, X_va_s, y_va, random_state=SEED + fold) # Use fold in seed for variation\n",
        "    models_xgb.append(xgb_model)\n",
        "\n",
        "    # XGBoost OOF and test predictions\n",
        "    oof_probs_xgb[va_mask] = xgb_model.predict_proba(X_va_s)\n",
        "    test_fold_probs_xgb.append(xgb_model.predict_proba(X_te_s))\n",
        "    print(f\"XGBoost F1 micro on validation: {f1_score(y_va, xgb_model.predict(X_va_s), average='micro'):.4f}\")\n",
        "\n",
        "    # NN Training and Prediction\n",
        "    sampler = None\n",
        "    if cfg.use_weighted_sampler:\n",
        "        class_sample_count = np.array([np.sum(y_tr == t) for t in np.unique(y_tr)])\n",
        "        weight_per_class = 1.0 / np.maximum(class_sample_count, 1)\n",
        "        weights = np.array([weight_per_class[t] for t in y_tr])\n",
        "        sampler = WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n",
        "\n",
        "    classes = np.unique(y_tr)\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_tr)\n",
        "    full_w = np.ones(3, dtype=np.float32)\n",
        "    for i, c in enumerate(classes):\n",
        "        full_w[c] = class_weights[i]\n",
        "    class_weights_t = torch.tensor(full_w, dtype=torch.float32, device=device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_t, label_smoothing=cfg.label_smoothing)\n",
        "\n",
        "    tr_loader = make_loader(X_tr_s, y_tr, batch_size=cfg.batch_size, shuffle=(sampler is None), sampler=sampler)\n",
        "    va_loader = make_loader(X_va_s, y_va, batch_size=cfg.batch_size, shuffle=False)\n",
        "    te_loader = make_loader(X_te_s, batch_size=cfg.batch_size, shuffle=False)\n",
        "\n",
        "    model = NeuralNetwork(in_dim=len(feature_cols), h1=cfg.hidden1, h2=cfg.hidden2, out_dim=3, dropout=cfg.dropout).to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    best_f1, best_state, no_improve = -1.0, None, 0\n",
        "    print(f\"\\n===== FOLD {fold}/{cfg.n_folds} \\u2014 NN Training \\u2014 train rows: {len(X_tr)}, val rows: {len(X_va)} ====\")\n",
        "    for epoch in range(1, cfg.epochs+1):\n",
        "        loss_tr, acc_tr = train_one_epoch(model, tr_loader, optimizer, criterion, scaler=scaler, max_grad_norm=cfg.max_grad_norm)\n",
        "        loss_va, acc_va, preds_va, tgts_va = evaluate(model, va_loader, criterion=criterion)\n",
        "        from sklearn.metrics import f1_score\n",
        "        f1_va = f1_score(tgts_va, preds_va, average=\"micro\")\n",
        "        print(f\"Epoch {epoch:02d} | loss_tr {loss_tr:.4f} acc_tr {acc_tr:.4f} | loss_va {loss_va:.4f} acc_va {acc_va:.4f} | f1_va {f1_va:.4f}\")\n",
        "        if f1_va > best_f1:\n",
        "            best_f1 = f1_va\n",
        "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= cfg.patience:\n",
        "                print(f\"Early stopping \\u2014 best F1: {best_f1:.4f}\")\n",
        "                break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
        "\n",
        "    _, _, preds_va, tgts_va = evaluate(model, va_loader, criterion=None)\n",
        "    oof_preds_nn[va_mask] = preds_va\n",
        "    va_probs_nn = predict_proba(model, va_loader)\n",
        "    oof_probs_nn[va_mask] = va_probs_nn\n",
        "\n",
        "    from sklearn.metrics import classification_report\n",
        "    rep = classification_report(tgts_va, preds_va, target_names=[\"no_pain\",\"low_pain\",\"high_pain\"], digits=4)\n",
        "    print(\"Fold NN report:\\n\", rep)\n",
        "\n",
        "    test_probs_nn = predict_proba(model, te_loader)\n",
        "    test_fold_probs_nn.append(test_probs_nn)\n",
        "\n",
        "# Calculate OOF F1 for NN\n",
        "oof_f1_micro_nn = f1_score(oof_true, oof_preds_nn, average=\"micro\")\n",
        "print(f\"\\nNN OOF F1 micro: {oof_f1_micro_nn:.4f}\")\n",
        "print(classification_report(oof_true, oof_preds_nn, target_names=[\"no_pain\",\"low_pain\",\"high_pain\"], digits=4))\n",
        "\n",
        "# Calculate OOF F1 for XGBoost\n",
        "oof_preds_xgb = np.argmax(oof_probs_xgb, axis=1)\n",
        "oof_f1_micro_xgb = f1_score(oof_true, oof_preds_xgb, average=\"micro\")\n",
        "print(f\"\\nXGBoost OOF F1 micro: {oof_f1_micro_xgb:.4f}\")\n",
        "print(classification_report(oof_true, oof_preds_xgb, target_names=[\"no_pain\",\"low_pain\",\"high_pain\"], digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "79eda810",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "79eda810",
        "outputId": "ea2ebb44-c68f-41a4-f1aa-2e4881ab72e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Ensembled OOF F1 micro: 0.9359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     no_pain     0.9632    0.9697    0.9665     81760\n",
            "    low_pain     0.8886    0.8668    0.8775     15040\n",
            "   high_pain     0.7593    0.7438    0.7514      8960\n",
            "\n",
            "    accuracy                         0.9359    105760\n",
            "   macro avg     0.8704    0.8601    0.8651    105760\n",
            "weighted avg     0.9353    0.9359    0.9356    105760\n",
            "\n",
            "label\n",
            "no_pain      1041\n",
            "low_pain      180\n",
            "high_pain     103\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"agg\",\n  \"rows\": 1324,\n  \"fields\": [\n    {\n      \"column\": \"sample_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 382,\n        \"min\": 0,\n        \"max\": 1323,\n        \"num_unique_values\": 1324,\n        \"samples\": [\n          888,\n          756,\n          1164\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p0\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1322,\n        \"samples\": [\n          0.984149158000946,\n          0.2695751190185547,\n          0.9437141418457031\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p1\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1324,\n        \"samples\": [\n          0.18200552463531494,\n          0.0407169833779335,\n          0.6073276996612549\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p2\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1324,\n        \"samples\": [\n          0.8104366064071655,\n          0.13518880307674408,\n          0.033845096826553345\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_label_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"no_pain\",\n          \"low_pain\",\n          \"high_pain\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "agg"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bdd97128-a388-4cc5-8c4c-d7a8f8901ead\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>p0</th>\n",
              "      <th>p1</th>\n",
              "      <th>p2</th>\n",
              "      <th>pred_label_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.853606</td>\n",
              "      <td>0.051745</td>\n",
              "      <td>0.094649</td>\n",
              "      <td>0</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.940932</td>\n",
              "      <td>0.016505</td>\n",
              "      <td>0.042564</td>\n",
              "      <td>0</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.952717</td>\n",
              "      <td>0.015500</td>\n",
              "      <td>0.031783</td>\n",
              "      <td>0</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.857329</td>\n",
              "      <td>0.028623</td>\n",
              "      <td>0.114048</td>\n",
              "      <td>0</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.897993</td>\n",
              "      <td>0.011758</td>\n",
              "      <td>0.090249</td>\n",
              "      <td>0</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdd97128-a388-4cc5-8c4c-d7a8f8901ead')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bdd97128-a388-4cc5-8c4c-d7a8f8901ead button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bdd97128-a388-4cc5-8c4c-d7a8f8901ead');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-de775806-8f41-46b0-ac50-354e0173f751\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de775806-8f41-46b0-ac50-354e0173f751')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-de775806-8f41-46b0-ac50-354e0173f751 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   sample_index        p0        p1        p2  pred_label_id    label\n",
              "0             0  0.853606  0.051745  0.094649              0  no_pain\n",
              "1             1  0.940932  0.016505  0.042564              0  no_pain\n",
              "2             2  0.952717  0.015500  0.031783              0  no_pain\n",
              "3             3  0.857329  0.028623  0.114048              0  no_pain\n",
              "4             4  0.897993  0.011758  0.090249              0  no_pain"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_mean_probs_nn = np.mean(np.stack(test_fold_probs_nn, axis=0), axis=0)\n",
        "test_mean_probs_xgb = np.mean(np.stack(test_fold_probs_xgb, axis=0), axis=0)\n",
        "\n",
        "# Ensemble OOF probabilities\n",
        "ensembled_oof_probs = (oof_probs_nn * ENSEMBLE_WEIGHT_NN) + (oof_probs_xgb * ENSEMBLE_WEIGHT_XGB)\n",
        "ensembled_oof_preds = np.argmax(ensembled_oof_probs, axis=1)\n",
        "\n",
        "# Calculate ensembled OOF F1 micro score\n",
        "oof_f1_micro_ensembled = f1_score(oof_true, ensembled_oof_preds, average=\"micro\")\n",
        "print(f\"\\nEnsembled OOF F1 micro: {oof_f1_micro_ensembled:.4f}\")\n",
        "print(classification_report(oof_true, ensembled_oof_preds, target_names=[\"no_pain\",\"low_pain\",\"high_pain\"], digits=4))\n",
        "\n",
        "# Ensemble test probabilities\n",
        "ensembled_test_probs = (test_mean_probs_nn * ENSEMBLE_WEIGHT_NN) + (test_mean_probs_xgb * ENSEMBLE_WEIGHT_XGB)\n",
        "\n",
        "df_test_pred = pd.DataFrame({\n",
        "    \"sample_index\": sid_test_all,\n",
        "    \"p0\": ensembled_test_probs[:,0],\n",
        "    \"p1\": ensembled_test_probs[:,1],\n",
        "    \"p2\": ensembled_test_probs[:,2],\n",
        "})\n",
        "agg = df_test_pred.groupby(\"sample_index\")[[\"p0\",\"p1\",\"p2\"]].mean().reset_index()\n",
        "agg[\"pred_label_id\"] = agg[[\"p0\",\"p1\",\"p2\"]].values.argmax(axis=1)\n",
        "inv_label_encoder = {0:\"no_pain\", 1:\"low_pain\", 2:\"high_pain\"}\n",
        "agg[\"label\"] = agg[\"pred_label_id\"].map(inv_label_encoder)\n",
        "print(agg[\"label\"].value_counts())\n",
        "agg.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vkzgz-yRNjBd",
      "metadata": {
        "id": "vkzgz-yRNjBd"
      },
      "source": [
        "## Salvataggio `submission.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nzx_SzM3NjSH",
      "metadata": {
        "id": "nzx_SzM3NjSH"
      },
      "outputs": [],
      "source": [
        "submission = agg[[\"sample_index\",\"label\"]].sort_values(\"sample_index\").reset_index(drop=True)\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"✔️ Salvato:\", os.path.abspath(\"submission.csv\"))\n",
        "submission.head()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
