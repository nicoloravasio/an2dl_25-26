{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "gPSIfSTkMXPS",
      "metadata": {
        "id": "gPSIfSTkMXPS"
      },
      "source": [
        "# AN2DL [2025–2026] — Time Series Classification (Stratified K-Fold, SMOTE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee673439",
      "metadata": {},
      "source": [
        "**NOTEBOOK BY thenegatives**\n",
        "\n",
        "\n",
        "**Burchini - Collovigh - Corti - Ravasio**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8lIVsqhmMXPU",
      "metadata": {
        "id": "8lIVsqhmMXPU"
      },
      "source": [
        "## Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oUWqjG2wMXPU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUWqjG2wMXPU",
        "outputId": "3da8f81b-4afb-4681-f379-01fe11c7a235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "Working dir: /gdrive/My Drive/DeepLearningChallenge\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/gdrive\")\n",
        "    current_dir = \"/gdrive/My Drive/DeepLearningChallenge/\"\n",
        "    try:\n",
        "        os.chdir(current_dir)\n",
        "    except FileNotFoundError:\n",
        "        print(\"⚠️ Aggiorna `current_dir` alla tua cartella dati.\")\n",
        "else:\n",
        "    current_dir = \".\"\n",
        "print(\"Working dir:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QQZSYnmdMXPU",
      "metadata": {
        "id": "QQZSYnmdMXPU"
      },
      "source": [
        "## Librerie & seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92r9KGEEMXPU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92r9KGEEMXPU",
        "outputId": "ba3537d6-3be2-43b2-9de1-5063524bd12c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, random, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        ")\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SEED = 42\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "set_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BYzCC2nwMXPV",
      "metadata": {
        "id": "BYzCC2nwMXPV"
      },
      "source": [
        "## Configurazione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F1Vq1-r4MXPV",
      "metadata": {
        "id": "F1Vq1-r4MXPV"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    n_folds = 6\n",
        "    epochs = 65\n",
        "    batch_size = 256\n",
        "    lr = 5e-4\n",
        "    weight_decay = 5e-4\n",
        "    max_grad_norm = 2.0\n",
        "    patience = 15\n",
        "    label_smoothing = 0.01\n",
        "    use_weighted_sampler = False\n",
        "\n",
        "    hidden1 = 384\n",
        "    hidden2 = 192\n",
        "    dropout = 0.25\n",
        "\n",
        "    train_csv = \"pirate_pain_train.csv\"\n",
        "    train_labels_csv = \"pirate_pain_train_labels.csv\"\n",
        "    test_csv = \"pirate_pain_test.csv\"\n",
        "\n",
        "cfg = CFG()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vla5r_MFMXPV",
      "metadata": {
        "id": "vla5r_MFMXPV"
      },
      "source": [
        "## Caricamento dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MZcTy0XAMXPV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZcTy0XAMXPV",
        "outputId": "5fc84c64-b5be-44ac-9f69-e07af3fa462a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train (time-step): (105760, 41) | Test (time-step): (211840, 40)\n",
            "Colonne: ['sample_index', 'time', 'pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4', 'n_legs', 'n_hands', 'n_eyes', 'joint_00'] ...\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(cfg.train_csv)\n",
        "labels_df = pd.read_csv(cfg.train_labels_csv)\n",
        "test_df  = pd.read_csv(cfg.test_csv)\n",
        "\n",
        "data = pd.merge(train_df, labels_df, on=\"sample_index\", how=\"left\")\n",
        "\n",
        "print(\"Train (time-step):\", data.shape, \"| Test (time-step):\", test_df.shape)\n",
        "print(\"Colonne:\", list(data.columns)[:10], \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32fVv0cBMXPW",
      "metadata": {
        "id": "32fVv0cBMXPW"
      },
      "source": [
        "## Selezione feature (35 input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SAENpgSUMXPW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAENpgSUMXPW",
        "outputId": "806be208-4fa6-4e56-b8ef-a5c25f837c8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numero feature: 35\n",
            "Esempio: ['pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4', 'joint_00', 'joint_01', 'joint_02', 'joint_03']\n"
          ]
        }
      ],
      "source": [
        "drop_cols = [\"time\", \"n_legs\", \"n_hands\", \"n_eyes\"]\n",
        "feature_cols = [c for c in data.columns if c not in ([\"sample_index\",\"label\"] + drop_cols)]\n",
        "assert len(feature_cols) == 35, f\"Attese 35 feature, trovate {len(feature_cols)}\"\n",
        "\n",
        "print(\"Numero feature:\", len(feature_cols))\n",
        "print(\"Esempio:\", feature_cols[:8])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J1ZSkI7sMXPX",
      "metadata": {
        "id": "J1ZSkI7sMXPX"
      },
      "source": [
        "## Encoding etichette e tabella sequenze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FPUaBNxHMXPX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPUaBNxHMXPX",
        "outputId": "753afa6c-2f35-4a4f-f72e-b56d6a5b5352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soggetti: 661\n",
            "label_encoded\n",
            "0    511\n",
            "1     94\n",
            "2     56\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "label_encoder = {\"no_pain\":0, \"low_pain\":1, \"high_pain\":2}\n",
        "inv_label_encoder = {v:k for k,v in label_encoder.items()}\n",
        "data[\"label_encoded\"] = data[\"label\"].map(label_encoder).astype(int)\n",
        "\n",
        "seq_df = data[[\"sample_index\",\"label_encoded\"]].drop_duplicates().reset_index(drop=True)\n",
        "print(\"Soggetti:\", len(seq_df))\n",
        "print(seq_df[\"label_encoded\"].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zSSYPiaBMXPX",
      "metadata": {
        "id": "zSSYPiaBMXPX"
      },
      "source": [
        "## Helper: scaler, dataset, modello (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cvx9Ej0cMXPX",
      "metadata": {
        "id": "cvx9Ej0cMXPX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "def fit_minmax(X):\n",
        "    mn = X.min(axis=0)\n",
        "    mx = X.max(axis=0)\n",
        "    denom = mx - mn\n",
        "    denom = np.where(denom == 0.0, 1.0, denom)\n",
        "    return mn, denom\n",
        "\n",
        "def apply_minmax(X, mn, denom):\n",
        "    return (X - mn) / denom\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self, in_dim=35, h1=128, h2=64, out_dim=3, dropout=0.10):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, h1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(h1, h2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(h2, out_dim)\n",
        "        )\n",
        "  def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def make_loader(X, y=None, batch_size=256, shuffle=False, sampler=None):\n",
        "    if y is None:\n",
        "        ds = TensorDataset(torch.from_numpy(X.astype(np.float32)))\n",
        "    else:\n",
        "        ds = TensorDataset(torch.from_numpy(X.astype(np.float32)),\n",
        "                           torch.from_numpy(y.astype(np.int64)))\n",
        "    return DataLoader(ds, batch_size=batch_size, shuffle=(sampler is None and shuffle),\n",
        "                      sampler=sampler, num_workers=2, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "noyWvsrAMXPX",
      "metadata": {
        "id": "noyWvsrAMXPX"
      },
      "source": [
        "## Train & Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LkhCdq28MXPX",
      "metadata": {
        "id": "LkhCdq28MXPX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "import torch\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, scaler=None, max_grad_norm=2.0):\n",
        "    model.train()\n",
        "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device); y = y.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast(enabled=(scaler is not None)):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            if max_grad_norm is not None:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if max_grad_norm is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        total_correct += (logits.argmax(1) == y).sum().item()\n",
        "        total_samples += x.size(0)\n",
        "    return total_loss/max(1,total_samples), total_correct/max(1,total_samples)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion=None):\n",
        "    model.eval()\n",
        "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
        "    all_preds, all_tgts = [], []\n",
        "    for x, y in loader:\n",
        "        x = x.to(device); y = y.to(device)\n",
        "        logits = model(x)\n",
        "        if criterion is not None:\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "        total_correct += (logits.argmax(1) == y).sum().item()\n",
        "        total_samples += x.size(0)\n",
        "        all_preds.append(logits.argmax(1).cpu().numpy())\n",
        "        all_tgts.append(y.cpu().numpy())\n",
        "    avg_loss = total_loss/max(1,total_samples) if total_samples>0 else None\n",
        "    acc = total_correct/max(1,total_samples) if total_samples>0 else None\n",
        "    return avg_loss, acc, np.concatenate(all_preds), np.concatenate(all_tgts)\n",
        "\n",
        "\n",
        "def _get_x_from_batch(batch):\n",
        "    # needed as batch may be a tensor, (x,), (x,y) or a dict\n",
        "    if isinstance(batch, (list, tuple)):\n",
        "        x = batch[0]\n",
        "    elif isinstance(batch, dict):\n",
        "        # try common keys\n",
        "        for k in ('x', 'inputs', 'features'):\n",
        "            if k in batch:\n",
        "                x = batch[k]\n",
        "                break\n",
        "        else:\n",
        "            raise ValueError(\"Impossibile estrarre le feature dal batch di tipo dict.\")\n",
        "    else:\n",
        "        x = batch\n",
        "    return x\n",
        "@torch.no_grad()\n",
        "def predict_proba(model, loader):\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            x = _get_x_from_batch(batch)\n",
        "            x = x.to(device, non_blocking=True)  # uses previously defined variable \"device\"\n",
        "            logits = model(x)\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            all_probs.append(probs.detach().cpu().numpy())\n",
        "    return np.concatenate(all_probs, axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_IuhYBOqMXPX",
      "metadata": {
        "id": "_IuhYBOqMXPX"
      },
      "source": [
        "## Stratified K-Fold (group-by `sample_index`) + OOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6Q1ArpvzMXPX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q1ArpvzMXPX",
        "outputId": "b52d6882-78b4-4c7b-8e41-342cf44fb4e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== FOLD 1/6 — train rows: 148640, val rows: 17760 =====\n",
            "Epoch 01 | loss_tr 0.7536 acc_tr 0.7108 | loss_va 0.6908 acc_va 0.7457 | f1_va 0.7457\n",
            "Epoch 02 | loss_tr 0.4848 acc_tr 0.8311 | loss_va 0.5910 acc_va 0.7892 | f1_va 0.7892\n",
            "Epoch 03 | loss_tr 0.3843 acc_tr 0.8702 | loss_va 0.5682 acc_va 0.8033 | f1_va 0.8033\n",
            "Epoch 04 | loss_tr 0.3249 acc_tr 0.8964 | loss_va 0.5251 acc_va 0.8285 | f1_va 0.8285\n",
            "Epoch 05 | loss_tr 0.2850 acc_tr 0.9148 | loss_va 0.4964 acc_va 0.8489 | f1_va 0.8489\n",
            "Epoch 06 | loss_tr 0.2586 acc_tr 0.9263 | loss_va 0.4570 acc_va 0.8725 | f1_va 0.8725\n",
            "Epoch 07 | loss_tr 0.2374 acc_tr 0.9359 | loss_va 0.4683 acc_va 0.8637 | f1_va 0.8637\n",
            "Epoch 08 | loss_tr 0.2220 acc_tr 0.9422 | loss_va 0.4634 acc_va 0.8747 | f1_va 0.8747\n",
            "Epoch 09 | loss_tr 0.2096 acc_tr 0.9463 | loss_va 0.4242 acc_va 0.8819 | f1_va 0.8819\n",
            "Epoch 10 | loss_tr 0.1987 acc_tr 0.9518 | loss_va 0.4102 acc_va 0.8939 | f1_va 0.8939\n",
            "Epoch 11 | loss_tr 0.1903 acc_tr 0.9547 | loss_va 0.4181 acc_va 0.8895 | f1_va 0.8895\n",
            "Epoch 12 | loss_tr 0.1832 acc_tr 0.9582 | loss_va 0.4313 acc_va 0.8827 | f1_va 0.8827\n",
            "Epoch 13 | loss_tr 0.1773 acc_tr 0.9594 | loss_va 0.4055 acc_va 0.9015 | f1_va 0.9015\n",
            "Epoch 14 | loss_tr 0.1714 acc_tr 0.9616 | loss_va 0.4038 acc_va 0.8981 | f1_va 0.8981\n",
            "Epoch 15 | loss_tr 0.1658 acc_tr 0.9639 | loss_va 0.3972 acc_va 0.9077 | f1_va 0.9077\n",
            "Epoch 16 | loss_tr 0.1621 acc_tr 0.9656 | loss_va 0.4255 acc_va 0.8881 | f1_va 0.8881\n",
            "Epoch 17 | loss_tr 0.1586 acc_tr 0.9667 | loss_va 0.4036 acc_va 0.9021 | f1_va 0.9021\n",
            "Epoch 18 | loss_tr 0.1553 acc_tr 0.9676 | loss_va 0.3959 acc_va 0.9037 | f1_va 0.9037\n",
            "Epoch 19 | loss_tr 0.1520 acc_tr 0.9695 | loss_va 0.3959 acc_va 0.9081 | f1_va 0.9081\n",
            "Epoch 20 | loss_tr 0.1494 acc_tr 0.9705 | loss_va 0.3866 acc_va 0.9148 | f1_va 0.9148\n",
            "Epoch 21 | loss_tr 0.1468 acc_tr 0.9711 | loss_va 0.4066 acc_va 0.9075 | f1_va 0.9075\n",
            "Epoch 22 | loss_tr 0.1452 acc_tr 0.9725 | loss_va 0.4000 acc_va 0.9060 | f1_va 0.9060\n",
            "Epoch 23 | loss_tr 0.1427 acc_tr 0.9726 | loss_va 0.4073 acc_va 0.9109 | f1_va 0.9109\n",
            "Epoch 24 | loss_tr 0.1405 acc_tr 0.9738 | loss_va 0.4057 acc_va 0.9046 | f1_va 0.9046\n",
            "Epoch 25 | loss_tr 0.1398 acc_tr 0.9742 | loss_va 0.3883 acc_va 0.9133 | f1_va 0.9133\n",
            "Epoch 26 | loss_tr 0.1373 acc_tr 0.9753 | loss_va 0.4122 acc_va 0.9025 | f1_va 0.9025\n",
            "Epoch 27 | loss_tr 0.1361 acc_tr 0.9752 | loss_va 0.4071 acc_va 0.9038 | f1_va 0.9038\n",
            "Epoch 28 | loss_tr 0.1345 acc_tr 0.9756 | loss_va 0.4000 acc_va 0.9053 | f1_va 0.9053\n",
            "Epoch 29 | loss_tr 0.1334 acc_tr 0.9767 | loss_va 0.4001 acc_va 0.9095 | f1_va 0.9095\n",
            "Epoch 30 | loss_tr 0.1322 acc_tr 0.9768 | loss_va 0.4042 acc_va 0.9126 | f1_va 0.9126\n",
            "Epoch 31 | loss_tr 0.1314 acc_tr 0.9777 | loss_va 0.3995 acc_va 0.9099 | f1_va 0.9099\n",
            "Epoch 32 | loss_tr 0.1305 acc_tr 0.9779 | loss_va 0.4037 acc_va 0.9209 | f1_va 0.9209\n",
            "Epoch 33 | loss_tr 0.1290 acc_tr 0.9787 | loss_va 0.3981 acc_va 0.9109 | f1_va 0.9109\n",
            "Epoch 34 | loss_tr 0.1282 acc_tr 0.9784 | loss_va 0.4007 acc_va 0.9166 | f1_va 0.9166\n",
            "Epoch 35 | loss_tr 0.1273 acc_tr 0.9789 | loss_va 0.3955 acc_va 0.9214 | f1_va 0.9214\n",
            "Epoch 36 | loss_tr 0.1258 acc_tr 0.9796 | loss_va 0.4274 acc_va 0.8992 | f1_va 0.8992\n",
            "Epoch 37 | loss_tr 0.1254 acc_tr 0.9797 | loss_va 0.4053 acc_va 0.9134 | f1_va 0.9134\n",
            "Epoch 38 | loss_tr 0.1252 acc_tr 0.9797 | loss_va 0.4187 acc_va 0.9083 | f1_va 0.9083\n",
            "Epoch 39 | loss_tr 0.1242 acc_tr 0.9805 | loss_va 0.3829 acc_va 0.9198 | f1_va 0.9198\n",
            "Epoch 40 | loss_tr 0.1242 acc_tr 0.9803 | loss_va 0.3886 acc_va 0.9182 | f1_va 0.9182\n",
            "Epoch 41 | loss_tr 0.1228 acc_tr 0.9807 | loss_va 0.3911 acc_va 0.9175 | f1_va 0.9175\n",
            "Epoch 42 | loss_tr 0.1234 acc_tr 0.9803 | loss_va 0.4098 acc_va 0.9123 | f1_va 0.9123\n",
            "Epoch 43 | loss_tr 0.1219 acc_tr 0.9812 | loss_va 0.3961 acc_va 0.9142 | f1_va 0.9142\n",
            "Epoch 44 | loss_tr 0.1226 acc_tr 0.9812 | loss_va 0.3974 acc_va 0.9177 | f1_va 0.9177\n",
            "Epoch 45 | loss_tr 0.1205 acc_tr 0.9817 | loss_va 0.3712 acc_va 0.9224 | f1_va 0.9224\n",
            "Epoch 46 | loss_tr 0.1208 acc_tr 0.9818 | loss_va 0.3683 acc_va 0.9240 | f1_va 0.9240\n",
            "Epoch 47 | loss_tr 0.1200 acc_tr 0.9815 | loss_va 0.3958 acc_va 0.9105 | f1_va 0.9105\n",
            "Epoch 48 | loss_tr 0.1202 acc_tr 0.9816 | loss_va 0.3790 acc_va 0.9243 | f1_va 0.9243\n",
            "Epoch 49 | loss_tr 0.1192 acc_tr 0.9823 | loss_va 0.3930 acc_va 0.9163 | f1_va 0.9163\n",
            "Epoch 50 | loss_tr 0.1198 acc_tr 0.9821 | loss_va 0.3854 acc_va 0.9192 | f1_va 0.9192\n",
            "Epoch 51 | loss_tr 0.1175 acc_tr 0.9829 | loss_va 0.3963 acc_va 0.9179 | f1_va 0.9179\n",
            "Epoch 52 | loss_tr 0.1191 acc_tr 0.9824 | loss_va 0.3883 acc_va 0.9185 | f1_va 0.9185\n",
            "Epoch 53 | loss_tr 0.1180 acc_tr 0.9828 | loss_va 0.4002 acc_va 0.9129 | f1_va 0.9129\n",
            "Epoch 54 | loss_tr 0.1179 acc_tr 0.9828 | loss_va 0.3755 acc_va 0.9172 | f1_va 0.9172\n",
            "Epoch 55 | loss_tr 0.1169 acc_tr 0.9829 | loss_va 0.4024 acc_va 0.9170 | f1_va 0.9170\n",
            "Epoch 56 | loss_tr 0.1171 acc_tr 0.9831 | loss_va 0.3878 acc_va 0.9262 | f1_va 0.9262\n",
            "Epoch 57 | loss_tr 0.1165 acc_tr 0.9830 | loss_va 0.4010 acc_va 0.9193 | f1_va 0.9193\n",
            "Epoch 58 | loss_tr 0.1165 acc_tr 0.9831 | loss_va 0.4027 acc_va 0.9207 | f1_va 0.9207\n",
            "Epoch 59 | loss_tr 0.1155 acc_tr 0.9836 | loss_va 0.3942 acc_va 0.9231 | f1_va 0.9231\n",
            "Epoch 60 | loss_tr 0.1154 acc_tr 0.9837 | loss_va 0.4052 acc_va 0.9068 | f1_va 0.9068\n",
            "Epoch 61 | loss_tr 0.1147 acc_tr 0.9836 | loss_va 0.4103 acc_va 0.9091 | f1_va 0.9091\n",
            "Epoch 62 | loss_tr 0.1148 acc_tr 0.9840 | loss_va 0.4190 acc_va 0.9132 | f1_va 0.9132\n",
            "Epoch 63 | loss_tr 0.1158 acc_tr 0.9837 | loss_va 0.3927 acc_va 0.9180 | f1_va 0.9180\n",
            "Epoch 64 | loss_tr 0.1146 acc_tr 0.9839 | loss_va 0.3927 acc_va 0.9144 | f1_va 0.9144\n",
            "Epoch 65 | loss_tr 0.1143 acc_tr 0.9842 | loss_va 0.3977 acc_va 0.9220 | f1_va 0.9220\n",
            "Fold report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     no_pain     0.9515    0.9704    0.9609     13760\n",
            "    low_pain     0.8525    0.9125    0.8815      2400\n",
            "   high_pain     0.7824    0.5663    0.6570      1600\n",
            "\n",
            "    accuracy                         0.9262     17760\n",
            "   macro avg     0.8621    0.8164    0.8331     17760\n",
            "weighted avg     0.9229    0.9262    0.9228     17760\n",
            "\n",
            "\n",
            "===== FOLD 2/6 — train rows: 148800, val rows: 17600 =====\n",
            "Epoch 01 | loss_tr 0.7674 acc_tr 0.6945 | loss_va 0.6593 acc_va 0.7323 | f1_va 0.7323\n",
            "Epoch 02 | loss_tr 0.4979 acc_tr 0.8200 | loss_va 0.4471 acc_va 0.8607 | f1_va 0.8607\n",
            "Epoch 03 | loss_tr 0.3889 acc_tr 0.8680 | loss_va 0.5082 acc_va 0.8056 | f1_va 0.8056\n",
            "Epoch 04 | loss_tr 0.3301 acc_tr 0.8923 | loss_va 0.4105 acc_va 0.8737 | f1_va 0.8737\n",
            "Epoch 05 | loss_tr 0.2927 acc_tr 0.9083 | loss_va 0.3497 acc_va 0.9082 | f1_va 0.9082\n",
            "Epoch 06 | loss_tr 0.2673 acc_tr 0.9204 | loss_va 0.4027 acc_va 0.8771 | f1_va 0.8771\n",
            "Epoch 07 | loss_tr 0.2492 acc_tr 0.9287 | loss_va 0.3607 acc_va 0.9036 | f1_va 0.9036\n",
            "Epoch 08 | loss_tr 0.2330 acc_tr 0.9353 | loss_va 0.3390 acc_va 0.9086 | f1_va 0.9086\n",
            "Epoch 09 | loss_tr 0.2203 acc_tr 0.9408 | loss_va 0.3133 acc_va 0.9361 | f1_va 0.9361\n",
            "Epoch 10 | loss_tr 0.2113 acc_tr 0.9451 | loss_va 0.3403 acc_va 0.9107 | f1_va 0.9107\n",
            "Epoch 11 | loss_tr 0.2016 acc_tr 0.9490 | loss_va 0.3191 acc_va 0.9221 | f1_va 0.9221\n",
            "Epoch 12 | loss_tr 0.1939 acc_tr 0.9521 | loss_va 0.3319 acc_va 0.9187 | f1_va 0.9187\n",
            "Epoch 13 | loss_tr 0.1869 acc_tr 0.9551 | loss_va 0.3177 acc_va 0.9280 | f1_va 0.9280\n",
            "Epoch 14 | loss_tr 0.1806 acc_tr 0.9574 | loss_va 0.3060 acc_va 0.9323 | f1_va 0.9323\n",
            "Epoch 15 | loss_tr 0.1772 acc_tr 0.9588 | loss_va 0.3215 acc_va 0.9239 | f1_va 0.9239\n",
            "Epoch 16 | loss_tr 0.1719 acc_tr 0.9606 | loss_va 0.2848 acc_va 0.9432 | f1_va 0.9432\n",
            "Epoch 17 | loss_tr 0.1666 acc_tr 0.9630 | loss_va 0.3053 acc_va 0.9345 | f1_va 0.9345\n",
            "Epoch 18 | loss_tr 0.1639 acc_tr 0.9639 | loss_va 0.3009 acc_va 0.9349 | f1_va 0.9349\n",
            "Epoch 19 | loss_tr 0.1604 acc_tr 0.9650 | loss_va 0.2956 acc_va 0.9437 | f1_va 0.9437\n",
            "Epoch 20 | loss_tr 0.1567 acc_tr 0.9666 | loss_va 0.2973 acc_va 0.9357 | f1_va 0.9357\n",
            "Epoch 21 | loss_tr 0.1549 acc_tr 0.9682 | loss_va 0.2791 acc_va 0.9445 | f1_va 0.9445\n",
            "Epoch 22 | loss_tr 0.1520 acc_tr 0.9690 | loss_va 0.2874 acc_va 0.9401 | f1_va 0.9401\n",
            "Epoch 23 | loss_tr 0.1506 acc_tr 0.9696 | loss_va 0.3017 acc_va 0.9353 | f1_va 0.9353\n",
            "Epoch 24 | loss_tr 0.1477 acc_tr 0.9708 | loss_va 0.2848 acc_va 0.9420 | f1_va 0.9420\n",
            "Epoch 25 | loss_tr 0.1457 acc_tr 0.9717 | loss_va 0.2770 acc_va 0.9469 | f1_va 0.9469\n",
            "Epoch 26 | loss_tr 0.1449 acc_tr 0.9717 | loss_va 0.2640 acc_va 0.9523 | f1_va 0.9523\n",
            "Epoch 27 | loss_tr 0.1417 acc_tr 0.9728 | loss_va 0.2689 acc_va 0.9474 | f1_va 0.9474\n",
            "Epoch 28 | loss_tr 0.1413 acc_tr 0.9735 | loss_va 0.2830 acc_va 0.9397 | f1_va 0.9397\n",
            "Epoch 29 | loss_tr 0.1394 acc_tr 0.9740 | loss_va 0.2732 acc_va 0.9455 | f1_va 0.9455\n",
            "Epoch 30 | loss_tr 0.1383 acc_tr 0.9745 | loss_va 0.2771 acc_va 0.9464 | f1_va 0.9464\n",
            "Epoch 31 | loss_tr 0.1383 acc_tr 0.9745 | loss_va 0.2661 acc_va 0.9464 | f1_va 0.9464\n",
            "Epoch 32 | loss_tr 0.1363 acc_tr 0.9750 | loss_va 0.2698 acc_va 0.9484 | f1_va 0.9484\n",
            "Epoch 33 | loss_tr 0.1347 acc_tr 0.9764 | loss_va 0.2858 acc_va 0.9435 | f1_va 0.9435\n",
            "Epoch 34 | loss_tr 0.1343 acc_tr 0.9759 | loss_va 0.2625 acc_va 0.9546 | f1_va 0.9546\n",
            "Epoch 35 | loss_tr 0.1332 acc_tr 0.9766 | loss_va 0.2689 acc_va 0.9499 | f1_va 0.9499\n",
            "Epoch 36 | loss_tr 0.1321 acc_tr 0.9770 | loss_va 0.2663 acc_va 0.9472 | f1_va 0.9472\n",
            "Epoch 37 | loss_tr 0.1314 acc_tr 0.9775 | loss_va 0.2744 acc_va 0.9481 | f1_va 0.9481\n",
            "Epoch 38 | loss_tr 0.1303 acc_tr 0.9780 | loss_va 0.2685 acc_va 0.9460 | f1_va 0.9460\n",
            "Epoch 39 | loss_tr 0.1300 acc_tr 0.9777 | loss_va 0.2526 acc_va 0.9518 | f1_va 0.9518\n",
            "Epoch 40 | loss_tr 0.1297 acc_tr 0.9781 | loss_va 0.2719 acc_va 0.9459 | f1_va 0.9459\n",
            "Epoch 41 | loss_tr 0.1296 acc_tr 0.9782 | loss_va 0.2779 acc_va 0.9507 | f1_va 0.9507\n",
            "Epoch 42 | loss_tr 0.1283 acc_tr 0.9788 | loss_va 0.2800 acc_va 0.9470 | f1_va 0.9470\n",
            "Epoch 43 | loss_tr 0.1271 acc_tr 0.9795 | loss_va 0.2764 acc_va 0.9482 | f1_va 0.9482\n",
            "Epoch 44 | loss_tr 0.1267 acc_tr 0.9794 | loss_va 0.2642 acc_va 0.9484 | f1_va 0.9484\n",
            "Epoch 45 | loss_tr 0.1263 acc_tr 0.9794 | loss_va 0.2715 acc_va 0.9485 | f1_va 0.9485\n",
            "Epoch 46 | loss_tr 0.1264 acc_tr 0.9797 | loss_va 0.2671 acc_va 0.9483 | f1_va 0.9483\n",
            "Epoch 47 | loss_tr 0.1253 acc_tr 0.9799 | loss_va 0.2656 acc_va 0.9484 | f1_va 0.9484\n",
            "Epoch 48 | loss_tr 0.1249 acc_tr 0.9801 | loss_va 0.2738 acc_va 0.9439 | f1_va 0.9439\n",
            "Epoch 49 | loss_tr 0.1240 acc_tr 0.9805 | loss_va 0.2850 acc_va 0.9452 | f1_va 0.9452\n",
            "Early stopping — best F1: 0.9546\n",
            "Fold report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     no_pain     0.9844    0.9740    0.9792     13600\n",
            "    low_pain     0.9377    0.9406    0.9392      2560\n",
            "   high_pain     0.7278    0.7965    0.7606      1440\n",
            "\n",
            "    accuracy                         0.9546     17600\n",
            "   macro avg     0.8833    0.9037    0.8930     17600\n",
            "weighted avg     0.9566    0.9546    0.9555     17600\n",
            "\n",
            "\n",
            "===== FOLD 3/6 — train rows: 148800, val rows: 17600 =====\n",
            "Epoch 01 | loss_tr 0.7520 acc_tr 0.7123 | loss_va 0.6460 acc_va 0.7828 | f1_va 0.7828\n",
            "Epoch 02 | loss_tr 0.4831 acc_tr 0.8344 | loss_va 0.6409 acc_va 0.7931 | f1_va 0.7931\n",
            "Epoch 03 | loss_tr 0.3666 acc_tr 0.8827 | loss_va 0.6564 acc_va 0.8069 | f1_va 0.8069\n",
            "Epoch 04 | loss_tr 0.3073 acc_tr 0.9079 | loss_va 0.6554 acc_va 0.8097 | f1_va 0.8097\n",
            "Epoch 05 | loss_tr 0.2714 acc_tr 0.9221 | loss_va 0.5767 acc_va 0.8590 | f1_va 0.8590\n",
            "Epoch 06 | loss_tr 0.2480 acc_tr 0.9312 | loss_va 0.6229 acc_va 0.8363 | f1_va 0.8363\n",
            "Epoch 07 | loss_tr 0.2282 acc_tr 0.9406 | loss_va 0.5665 acc_va 0.8720 | f1_va 0.8720\n",
            "Epoch 08 | loss_tr 0.2143 acc_tr 0.9468 | loss_va 0.5777 acc_va 0.8735 | f1_va 0.8735\n",
            "Epoch 09 | loss_tr 0.2032 acc_tr 0.9513 | loss_va 0.5693 acc_va 0.8723 | f1_va 0.8723\n",
            "Epoch 10 | loss_tr 0.1926 acc_tr 0.9551 | loss_va 0.5350 acc_va 0.8865 | f1_va 0.8865\n",
            "Epoch 11 | loss_tr 0.1853 acc_tr 0.9586 | loss_va 0.5493 acc_va 0.8762 | f1_va 0.8762\n",
            "Epoch 12 | loss_tr 0.1782 acc_tr 0.9617 | loss_va 0.5413 acc_va 0.8895 | f1_va 0.8895\n",
            "Epoch 13 | loss_tr 0.1709 acc_tr 0.9641 | loss_va 0.5142 acc_va 0.8890 | f1_va 0.8890\n",
            "Epoch 14 | loss_tr 0.1661 acc_tr 0.9662 | loss_va 0.5261 acc_va 0.8920 | f1_va 0.8920\n",
            "Epoch 15 | loss_tr 0.1602 acc_tr 0.9680 | loss_va 0.5516 acc_va 0.8774 | f1_va 0.8774\n",
            "Epoch 16 | loss_tr 0.1562 acc_tr 0.9694 | loss_va 0.5337 acc_va 0.8844 | f1_va 0.8844\n",
            "Epoch 17 | loss_tr 0.1523 acc_tr 0.9712 | loss_va 0.5206 acc_va 0.8954 | f1_va 0.8954\n",
            "Epoch 18 | loss_tr 0.1489 acc_tr 0.9725 | loss_va 0.5232 acc_va 0.8878 | f1_va 0.8878\n",
            "Epoch 19 | loss_tr 0.1462 acc_tr 0.9735 | loss_va 0.5146 acc_va 0.8897 | f1_va 0.8897\n",
            "Epoch 20 | loss_tr 0.1446 acc_tr 0.9738 | loss_va 0.5121 acc_va 0.8947 | f1_va 0.8947\n",
            "Epoch 21 | loss_tr 0.1418 acc_tr 0.9753 | loss_va 0.5118 acc_va 0.8877 | f1_va 0.8877\n",
            "Epoch 22 | loss_tr 0.1402 acc_tr 0.9754 | loss_va 0.5002 acc_va 0.8915 | f1_va 0.8915\n",
            "Epoch 23 | loss_tr 0.1374 acc_tr 0.9766 | loss_va 0.4824 acc_va 0.8959 | f1_va 0.8959\n",
            "Epoch 24 | loss_tr 0.1357 acc_tr 0.9772 | loss_va 0.5043 acc_va 0.8985 | f1_va 0.8985\n",
            "Epoch 25 | loss_tr 0.1345 acc_tr 0.9775 | loss_va 0.4719 acc_va 0.8955 | f1_va 0.8955\n",
            "Epoch 26 | loss_tr 0.1325 acc_tr 0.9785 | loss_va 0.4774 acc_va 0.9019 | f1_va 0.9019\n",
            "Epoch 27 | loss_tr 0.1308 acc_tr 0.9789 | loss_va 0.5007 acc_va 0.8912 | f1_va 0.8912\n",
            "Epoch 28 | loss_tr 0.1292 acc_tr 0.9797 | loss_va 0.4837 acc_va 0.8934 | f1_va 0.8934\n",
            "Epoch 29 | loss_tr 0.1280 acc_tr 0.9803 | loss_va 0.4763 acc_va 0.9003 | f1_va 0.9003\n",
            "Epoch 30 | loss_tr 0.1271 acc_tr 0.9808 | loss_va 0.4762 acc_va 0.8952 | f1_va 0.8952\n",
            "Epoch 31 | loss_tr 0.1265 acc_tr 0.9808 | loss_va 0.4832 acc_va 0.8956 | f1_va 0.8956\n",
            "Epoch 32 | loss_tr 0.1251 acc_tr 0.9813 | loss_va 0.4678 acc_va 0.9018 | f1_va 0.9018\n",
            "Epoch 33 | loss_tr 0.1232 acc_tr 0.9820 | loss_va 0.4536 acc_va 0.9113 | f1_va 0.9113\n",
            "Epoch 34 | loss_tr 0.1228 acc_tr 0.9823 | loss_va 0.4511 acc_va 0.9052 | f1_va 0.9052\n",
            "Epoch 35 | loss_tr 0.1222 acc_tr 0.9823 | loss_va 0.4471 acc_va 0.9103 | f1_va 0.9103\n",
            "Epoch 36 | loss_tr 0.1215 acc_tr 0.9827 | loss_va 0.4453 acc_va 0.8966 | f1_va 0.8966\n",
            "Epoch 37 | loss_tr 0.1206 acc_tr 0.9829 | loss_va 0.4486 acc_va 0.9096 | f1_va 0.9096\n",
            "Epoch 38 | loss_tr 0.1193 acc_tr 0.9838 | loss_va 0.4173 acc_va 0.9149 | f1_va 0.9149\n",
            "Epoch 39 | loss_tr 0.1197 acc_tr 0.9837 | loss_va 0.4514 acc_va 0.9092 | f1_va 0.9092\n",
            "Epoch 40 | loss_tr 0.1180 acc_tr 0.9838 | loss_va 0.4383 acc_va 0.9054 | f1_va 0.9054\n",
            "Epoch 41 | loss_tr 0.1183 acc_tr 0.9841 | loss_va 0.4643 acc_va 0.9061 | f1_va 0.9061\n",
            "Epoch 42 | loss_tr 0.1178 acc_tr 0.9843 | loss_va 0.4351 acc_va 0.9123 | f1_va 0.9123\n",
            "Epoch 43 | loss_tr 0.1164 acc_tr 0.9845 | loss_va 0.4467 acc_va 0.9080 | f1_va 0.9080\n",
            "Epoch 44 | loss_tr 0.1151 acc_tr 0.9852 | loss_va 0.4722 acc_va 0.8961 | f1_va 0.8961\n",
            "Epoch 45 | loss_tr 0.1156 acc_tr 0.9847 | loss_va 0.4271 acc_va 0.9125 | f1_va 0.9125\n",
            "Epoch 46 | loss_tr 0.1158 acc_tr 0.9849 | loss_va 0.4268 acc_va 0.9120 | f1_va 0.9120\n",
            "Epoch 47 | loss_tr 0.1146 acc_tr 0.9855 | loss_va 0.4516 acc_va 0.9045 | f1_va 0.9045\n",
            "Epoch 48 | loss_tr 0.1141 acc_tr 0.9855 | loss_va 0.4408 acc_va 0.9097 | f1_va 0.9097\n",
            "Epoch 49 | loss_tr 0.1146 acc_tr 0.9855 | loss_va 0.4356 acc_va 0.9074 | f1_va 0.9074\n",
            "Epoch 50 | loss_tr 0.1135 acc_tr 0.9859 | loss_va 0.4161 acc_va 0.9122 | f1_va 0.9122\n",
            "Epoch 51 | loss_tr 0.1132 acc_tr 0.9857 | loss_va 0.4217 acc_va 0.9141 | f1_va 0.9141\n",
            "Epoch 52 | loss_tr 0.1129 acc_tr 0.9862 | loss_va 0.4561 acc_va 0.9032 | f1_va 0.9032\n",
            "Epoch 53 | loss_tr 0.1113 acc_tr 0.9867 | loss_va 0.4616 acc_va 0.9077 | f1_va 0.9077\n",
            "Early stopping — best F1: 0.9149\n",
            "Fold report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     no_pain     0.9540    0.9570    0.9555     13600\n",
            "    low_pain     0.8281    0.8375    0.8328      2560\n",
            "   high_pain     0.6901    0.6556    0.6724      1440\n",
            "\n",
            "    accuracy                         0.9149     17600\n",
            "   macro avg     0.8240    0.8167    0.8202     17600\n",
            "weighted avg     0.9141    0.9149    0.9145     17600\n",
            "\n",
            "\n",
            "===== FOLD 4/6 — train rows: 148800, val rows: 17600 =====\n",
            "Epoch 01 | loss_tr 0.7612 acc_tr 0.7013 | loss_va 0.6664 acc_va 0.7868 | f1_va 0.7868\n",
            "Epoch 02 | loss_tr 0.4778 acc_tr 0.8333 | loss_va 0.6037 acc_va 0.8181 | f1_va 0.8181\n",
            "Epoch 03 | loss_tr 0.3636 acc_tr 0.8832 | loss_va 0.6233 acc_va 0.8278 | f1_va 0.8278\n",
            "Epoch 04 | loss_tr 0.3052 acc_tr 0.9084 | loss_va 0.5670 acc_va 0.8532 | f1_va 0.8532\n",
            "Epoch 05 | loss_tr 0.2725 acc_tr 0.9209 | loss_va 0.5577 acc_va 0.8741 | f1_va 0.8741\n",
            "Epoch 06 | loss_tr 0.2488 acc_tr 0.9304 | loss_va 0.5376 acc_va 0.8886 | f1_va 0.8886\n",
            "Epoch 07 | loss_tr 0.2345 acc_tr 0.9364 | loss_va 0.5367 acc_va 0.8770 | f1_va 0.8770\n",
            "Epoch 08 | loss_tr 0.2216 acc_tr 0.9420 | loss_va 0.5510 acc_va 0.8824 | f1_va 0.8824\n",
            "Epoch 09 | loss_tr 0.2095 acc_tr 0.9477 | loss_va 0.5201 acc_va 0.8848 | f1_va 0.8848\n",
            "Epoch 10 | loss_tr 0.2017 acc_tr 0.9503 | loss_va 0.5035 acc_va 0.8887 | f1_va 0.8887\n",
            "Epoch 11 | loss_tr 0.1941 acc_tr 0.9536 | loss_va 0.4683 acc_va 0.8860 | f1_va 0.8860\n",
            "Epoch 12 | loss_tr 0.1851 acc_tr 0.9568 | loss_va 0.4901 acc_va 0.8884 | f1_va 0.8884\n",
            "Epoch 13 | loss_tr 0.1801 acc_tr 0.9582 | loss_va 0.4971 acc_va 0.8831 | f1_va 0.8831\n",
            "Epoch 14 | loss_tr 0.1741 acc_tr 0.9606 | loss_va 0.4657 acc_va 0.8875 | f1_va 0.8875\n",
            "Epoch 15 | loss_tr 0.1692 acc_tr 0.9627 | loss_va 0.4436 acc_va 0.9014 | f1_va 0.9014\n",
            "Epoch 16 | loss_tr 0.1661 acc_tr 0.9638 | loss_va 0.4477 acc_va 0.8894 | f1_va 0.8894\n",
            "Epoch 17 | loss_tr 0.1607 acc_tr 0.9661 | loss_va 0.4219 acc_va 0.8970 | f1_va 0.8970\n",
            "Epoch 18 | loss_tr 0.1581 acc_tr 0.9667 | loss_va 0.4219 acc_va 0.8978 | f1_va 0.8978\n",
            "Epoch 19 | loss_tr 0.1548 acc_tr 0.9687 | loss_va 0.4184 acc_va 0.9105 | f1_va 0.9105\n",
            "Epoch 20 | loss_tr 0.1524 acc_tr 0.9688 | loss_va 0.4495 acc_va 0.8910 | f1_va 0.8910\n",
            "Epoch 21 | loss_tr 0.1500 acc_tr 0.9703 | loss_va 0.4289 acc_va 0.8993 | f1_va 0.8993\n",
            "Epoch 22 | loss_tr 0.1470 acc_tr 0.9711 | loss_va 0.4285 acc_va 0.8960 | f1_va 0.8960\n",
            "Epoch 23 | loss_tr 0.1462 acc_tr 0.9715 | loss_va 0.4453 acc_va 0.8981 | f1_va 0.8981\n",
            "Epoch 24 | loss_tr 0.1436 acc_tr 0.9727 | loss_va 0.4257 acc_va 0.9033 | f1_va 0.9033\n",
            "Epoch 25 | loss_tr 0.1418 acc_tr 0.9739 | loss_va 0.4301 acc_va 0.8957 | f1_va 0.8957\n",
            "Epoch 26 | loss_tr 0.1410 acc_tr 0.9740 | loss_va 0.4464 acc_va 0.8892 | f1_va 0.8892\n",
            "Epoch 27 | loss_tr 0.1388 acc_tr 0.9749 | loss_va 0.4392 acc_va 0.8993 | f1_va 0.8993\n",
            "Epoch 28 | loss_tr 0.1377 acc_tr 0.9752 | loss_va 0.4433 acc_va 0.8998 | f1_va 0.8998\n",
            "Epoch 29 | loss_tr 0.1367 acc_tr 0.9757 | loss_va 0.4197 acc_va 0.8991 | f1_va 0.8991\n",
            "Epoch 30 | loss_tr 0.1355 acc_tr 0.9764 | loss_va 0.4287 acc_va 0.8959 | f1_va 0.8959\n",
            "Epoch 31 | loss_tr 0.1339 acc_tr 0.9764 | loss_va 0.4369 acc_va 0.9045 | f1_va 0.9045\n",
            "Epoch 32 | loss_tr 0.1331 acc_tr 0.9769 | loss_va 0.4543 acc_va 0.8975 | f1_va 0.8975\n",
            "Epoch 33 | loss_tr 0.1322 acc_tr 0.9771 | loss_va 0.4325 acc_va 0.8994 | f1_va 0.8994\n",
            "Epoch 34 | loss_tr 0.1313 acc_tr 0.9776 | loss_va 0.4426 acc_va 0.8990 | f1_va 0.8990\n",
            "Early stopping — best F1: 0.9105\n",
            "Fold report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     no_pain     0.9448    0.9565    0.9506     13600\n",
            "    low_pain     0.8677    0.8812    0.8744      2560\n",
            "   high_pain     0.6169    0.5278    0.5689      1440\n",
            "\n",
            "    accuracy                         0.9105     17600\n",
            "   macro avg     0.8098    0.7885    0.7980     17600\n",
            "weighted avg     0.9068    0.9105    0.9083     17600\n",
            "\n",
            "\n",
            "===== FOLD 5/6 — train rows: 148800, val rows: 17600 =====\n",
            "Epoch 01 | loss_tr 0.7655 acc_tr 0.6950 | loss_va 0.6368 acc_va 0.7859 | f1_va 0.7859\n",
            "Epoch 02 | loss_tr 0.4955 acc_tr 0.8165 | loss_va 0.5633 acc_va 0.8061 | f1_va 0.8061\n",
            "Epoch 03 | loss_tr 0.3812 acc_tr 0.8680 | loss_va 0.5053 acc_va 0.8326 | f1_va 0.8326\n",
            "Epoch 04 | loss_tr 0.3177 acc_tr 0.8966 | loss_va 0.4201 acc_va 0.8762 | f1_va 0.8762\n",
            "Epoch 05 | loss_tr 0.2819 acc_tr 0.9125 | loss_va 0.4146 acc_va 0.8762 | f1_va 0.8762\n",
            "Epoch 06 | loss_tr 0.2555 acc_tr 0.9237 | loss_va 0.3993 acc_va 0.8855 | f1_va 0.8855\n",
            "Epoch 07 | loss_tr 0.2353 acc_tr 0.9336 | loss_va 0.3855 acc_va 0.8823 | f1_va 0.8823\n",
            "Epoch 08 | loss_tr 0.2198 acc_tr 0.9403 | loss_va 0.3792 acc_va 0.8980 | f1_va 0.8980\n",
            "Epoch 09 | loss_tr 0.2073 acc_tr 0.9448 | loss_va 0.3686 acc_va 0.8899 | f1_va 0.8899\n",
            "Epoch 10 | loss_tr 0.1981 acc_tr 0.9497 | loss_va 0.3503 acc_va 0.8975 | f1_va 0.8975\n",
            "Epoch 11 | loss_tr 0.1907 acc_tr 0.9531 | loss_va 0.3379 acc_va 0.9037 | f1_va 0.9037\n",
            "Epoch 12 | loss_tr 0.1828 acc_tr 0.9561 | loss_va 0.3682 acc_va 0.8910 | f1_va 0.8910\n",
            "Epoch 13 | loss_tr 0.1754 acc_tr 0.9587 | loss_va 0.3738 acc_va 0.8995 | f1_va 0.8995\n",
            "Epoch 14 | loss_tr 0.1703 acc_tr 0.9608 | loss_va 0.3295 acc_va 0.9089 | f1_va 0.9089\n",
            "Epoch 15 | loss_tr 0.1647 acc_tr 0.9635 | loss_va 0.3328 acc_va 0.9158 | f1_va 0.9158\n",
            "Epoch 16 | loss_tr 0.1606 acc_tr 0.9649 | loss_va 0.3470 acc_va 0.9053 | f1_va 0.9053\n",
            "Epoch 17 | loss_tr 0.1569 acc_tr 0.9666 | loss_va 0.3181 acc_va 0.9153 | f1_va 0.9153\n",
            "Epoch 18 | loss_tr 0.1549 acc_tr 0.9673 | loss_va 0.3334 acc_va 0.9184 | f1_va 0.9184\n",
            "Epoch 19 | loss_tr 0.1518 acc_tr 0.9685 | loss_va 0.3132 acc_va 0.9186 | f1_va 0.9186\n",
            "Epoch 20 | loss_tr 0.1481 acc_tr 0.9706 | loss_va 0.3068 acc_va 0.9217 | f1_va 0.9217\n",
            "Epoch 21 | loss_tr 0.1461 acc_tr 0.9709 | loss_va 0.3072 acc_va 0.9305 | f1_va 0.9305\n",
            "Epoch 22 | loss_tr 0.1438 acc_tr 0.9724 | loss_va 0.3126 acc_va 0.9193 | f1_va 0.9193\n",
            "Epoch 23 | loss_tr 0.1424 acc_tr 0.9726 | loss_va 0.3310 acc_va 0.9137 | f1_va 0.9137\n",
            "Epoch 24 | loss_tr 0.1406 acc_tr 0.9734 | loss_va 0.3247 acc_va 0.9185 | f1_va 0.9185\n",
            "Epoch 25 | loss_tr 0.1386 acc_tr 0.9744 | loss_va 0.3043 acc_va 0.9277 | f1_va 0.9277\n",
            "Epoch 26 | loss_tr 0.1366 acc_tr 0.9752 | loss_va 0.3091 acc_va 0.9255 | f1_va 0.9255\n",
            "Epoch 27 | loss_tr 0.1351 acc_tr 0.9756 | loss_va 0.3311 acc_va 0.9175 | f1_va 0.9175\n",
            "Epoch 28 | loss_tr 0.1346 acc_tr 0.9753 | loss_va 0.3247 acc_va 0.9170 | f1_va 0.9170\n",
            "Epoch 29 | loss_tr 0.1328 acc_tr 0.9766 | loss_va 0.2941 acc_va 0.9334 | f1_va 0.9334\n",
            "Epoch 30 | loss_tr 0.1325 acc_tr 0.9766 | loss_va 0.3231 acc_va 0.9189 | f1_va 0.9189\n",
            "Epoch 31 | loss_tr 0.1302 acc_tr 0.9776 | loss_va 0.3237 acc_va 0.9199 | f1_va 0.9199\n",
            "Epoch 32 | loss_tr 0.1290 acc_tr 0.9783 | loss_va 0.3065 acc_va 0.9206 | f1_va 0.9206\n",
            "Epoch 33 | loss_tr 0.1284 acc_tr 0.9788 | loss_va 0.3130 acc_va 0.9185 | f1_va 0.9185\n",
            "Epoch 34 | loss_tr 0.1284 acc_tr 0.9789 | loss_va 0.3400 acc_va 0.9133 | f1_va 0.9133\n",
            "Epoch 35 | loss_tr 0.1268 acc_tr 0.9791 | loss_va 0.2992 acc_va 0.9322 | f1_va 0.9322\n",
            "Epoch 36 | loss_tr 0.1260 acc_tr 0.9797 | loss_va 0.2999 acc_va 0.9225 | f1_va 0.9225\n",
            "Epoch 37 | loss_tr 0.1257 acc_tr 0.9795 | loss_va 0.3105 acc_va 0.9277 | f1_va 0.9277\n",
            "Epoch 38 | loss_tr 0.1247 acc_tr 0.9800 | loss_va 0.3157 acc_va 0.9213 | f1_va 0.9213\n",
            "Epoch 39 | loss_tr 0.1237 acc_tr 0.9806 | loss_va 0.3288 acc_va 0.9201 | f1_va 0.9201\n",
            "Epoch 40 | loss_tr 0.1231 acc_tr 0.9806 | loss_va 0.3338 acc_va 0.9289 | f1_va 0.9289\n",
            "Epoch 41 | loss_tr 0.1228 acc_tr 0.9810 | loss_va 0.3231 acc_va 0.9277 | f1_va 0.9277\n",
            "Epoch 42 | loss_tr 0.1219 acc_tr 0.9810 | loss_va 0.3333 acc_va 0.9296 | f1_va 0.9296\n",
            "Epoch 43 | loss_tr 0.1217 acc_tr 0.9812 | loss_va 0.2977 acc_va 0.9274 | f1_va 0.9274\n",
            "Epoch 44 | loss_tr 0.1205 acc_tr 0.9820 | loss_va 0.3394 acc_va 0.9199 | f1_va 0.9199\n",
            "Early stopping — best F1: 0.9334\n",
            "Fold report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     no_pain     0.9598    0.9633    0.9615     13600\n",
            "    low_pain     0.9912    0.7500    0.8539      2560\n",
            "   high_pain     0.6985    0.9764    0.8144      1440\n",
            "\n",
            "    accuracy                         0.9334     17600\n",
            "   macro avg     0.8832    0.8966    0.8766     17600\n",
            "weighted avg     0.9430    0.9334    0.9338     17600\n",
            "\n",
            "\n",
            "===== FOLD 6/6 — train rows: 148960, val rows: 17600 =====\n",
            "Epoch 01 | loss_tr 0.7474 acc_tr 0.7145 | loss_va 0.7024 acc_va 0.7454 | f1_va 0.7454\n",
            "Epoch 02 | loss_tr 0.4779 acc_tr 0.8356 | loss_va 0.5845 acc_va 0.8086 | f1_va 0.8086\n",
            "Epoch 03 | loss_tr 0.3727 acc_tr 0.8800 | loss_va 0.6153 acc_va 0.7827 | f1_va 0.7827\n",
            "Epoch 04 | loss_tr 0.3150 acc_tr 0.9035 | loss_va 0.5709 acc_va 0.8193 | f1_va 0.8193\n",
            "Epoch 05 | loss_tr 0.2783 acc_tr 0.9189 | loss_va 0.5498 acc_va 0.8179 | f1_va 0.8179\n",
            "Epoch 06 | loss_tr 0.2512 acc_tr 0.9305 | loss_va 0.4941 acc_va 0.8466 | f1_va 0.8466\n",
            "Epoch 07 | loss_tr 0.2319 acc_tr 0.9371 | loss_va 0.5206 acc_va 0.8409 | f1_va 0.8409\n",
            "Epoch 08 | loss_tr 0.2202 acc_tr 0.9420 | loss_va 0.4731 acc_va 0.8695 | f1_va 0.8695\n",
            "Epoch 09 | loss_tr 0.2073 acc_tr 0.9480 | loss_va 0.4991 acc_va 0.8672 | f1_va 0.8672\n",
            "Epoch 10 | loss_tr 0.1977 acc_tr 0.9514 | loss_va 0.5191 acc_va 0.8516 | f1_va 0.8516\n",
            "Epoch 11 | loss_tr 0.1911 acc_tr 0.9533 | loss_va 0.4934 acc_va 0.8715 | f1_va 0.8715\n",
            "Epoch 12 | loss_tr 0.1817 acc_tr 0.9573 | loss_va 0.4746 acc_va 0.8700 | f1_va 0.8700\n",
            "Epoch 13 | loss_tr 0.1766 acc_tr 0.9596 | loss_va 0.4500 acc_va 0.8795 | f1_va 0.8795\n",
            "Epoch 14 | loss_tr 0.1710 acc_tr 0.9613 | loss_va 0.5106 acc_va 0.8780 | f1_va 0.8780\n",
            "Epoch 15 | loss_tr 0.1665 acc_tr 0.9630 | loss_va 0.4621 acc_va 0.8834 | f1_va 0.8834\n",
            "Epoch 16 | loss_tr 0.1608 acc_tr 0.9659 | loss_va 0.4392 acc_va 0.8868 | f1_va 0.8868\n",
            "Epoch 17 | loss_tr 0.1571 acc_tr 0.9675 | loss_va 0.5103 acc_va 0.8706 | f1_va 0.8706\n",
            "Epoch 18 | loss_tr 0.1543 acc_tr 0.9677 | loss_va 0.4928 acc_va 0.8699 | f1_va 0.8699\n",
            "Epoch 19 | loss_tr 0.1504 acc_tr 0.9694 | loss_va 0.4886 acc_va 0.8769 | f1_va 0.8769\n",
            "Epoch 20 | loss_tr 0.1479 acc_tr 0.9704 | loss_va 0.4434 acc_va 0.8915 | f1_va 0.8915\n",
            "Epoch 21 | loss_tr 0.1449 acc_tr 0.9719 | loss_va 0.4203 acc_va 0.8977 | f1_va 0.8977\n",
            "Epoch 22 | loss_tr 0.1423 acc_tr 0.9726 | loss_va 0.4581 acc_va 0.8877 | f1_va 0.8877\n",
            "Epoch 23 | loss_tr 0.1419 acc_tr 0.9726 | loss_va 0.4377 acc_va 0.8928 | f1_va 0.8928\n",
            "Epoch 24 | loss_tr 0.1389 acc_tr 0.9743 | loss_va 0.4467 acc_va 0.8831 | f1_va 0.8831\n",
            "Epoch 25 | loss_tr 0.1370 acc_tr 0.9746 | loss_va 0.4334 acc_va 0.8927 | f1_va 0.8927\n",
            "Epoch 26 | loss_tr 0.1359 acc_tr 0.9757 | loss_va 0.4640 acc_va 0.8946 | f1_va 0.8946\n",
            "Epoch 27 | loss_tr 0.1339 acc_tr 0.9763 | loss_va 0.4553 acc_va 0.8922 | f1_va 0.8922\n",
            "Epoch 28 | loss_tr 0.1330 acc_tr 0.9762 | loss_va 0.4534 acc_va 0.8927 | f1_va 0.8927\n",
            "Epoch 29 | loss_tr 0.1307 acc_tr 0.9775 | loss_va 0.4390 acc_va 0.8936 | f1_va 0.8936\n",
            "Epoch 30 | loss_tr 0.1302 acc_tr 0.9774 | loss_va 0.4064 acc_va 0.8945 | f1_va 0.8945\n",
            "Epoch 31 | loss_tr 0.1294 acc_tr 0.9784 | loss_va 0.4074 acc_va 0.9041 | f1_va 0.9041\n",
            "Epoch 32 | loss_tr 0.1283 acc_tr 0.9785 | loss_va 0.4501 acc_va 0.8941 | f1_va 0.8941\n",
            "Epoch 33 | loss_tr 0.1267 acc_tr 0.9790 | loss_va 0.4734 acc_va 0.8955 | f1_va 0.8955\n",
            "Epoch 34 | loss_tr 0.1265 acc_tr 0.9795 | loss_va 0.4606 acc_va 0.9003 | f1_va 0.9003\n",
            "Epoch 35 | loss_tr 0.1257 acc_tr 0.9793 | loss_va 0.4318 acc_va 0.9024 | f1_va 0.9024\n",
            "Epoch 36 | loss_tr 0.1245 acc_tr 0.9800 | loss_va 0.4637 acc_va 0.8968 | f1_va 0.8968\n",
            "Epoch 37 | loss_tr 0.1245 acc_tr 0.9804 | loss_va 0.4339 acc_va 0.9007 | f1_va 0.9007\n",
            "Epoch 38 | loss_tr 0.1228 acc_tr 0.9807 | loss_va 0.4988 acc_va 0.8922 | f1_va 0.8922\n",
            "Epoch 39 | loss_tr 0.1228 acc_tr 0.9806 | loss_va 0.4604 acc_va 0.8977 | f1_va 0.8977\n",
            "Epoch 40 | loss_tr 0.1224 acc_tr 0.9806 | loss_va 0.4252 acc_va 0.8922 | f1_va 0.8922\n",
            "Epoch 41 | loss_tr 0.1227 acc_tr 0.9808 | loss_va 0.4506 acc_va 0.8976 | f1_va 0.8976\n",
            "Epoch 42 | loss_tr 0.1211 acc_tr 0.9816 | loss_va 0.4620 acc_va 0.9021 | f1_va 0.9021\n",
            "Epoch 43 | loss_tr 0.1203 acc_tr 0.9816 | loss_va 0.4356 acc_va 0.8977 | f1_va 0.8977\n",
            "Epoch 44 | loss_tr 0.1203 acc_tr 0.9818 | loss_va 0.4668 acc_va 0.9019 | f1_va 0.9019\n",
            "Epoch 45 | loss_tr 0.1189 acc_tr 0.9821 | loss_va 0.4288 acc_va 0.8993 | f1_va 0.8993\n",
            "Epoch 46 | loss_tr 0.1192 acc_tr 0.9822 | loss_va 0.4324 acc_va 0.9072 | f1_va 0.9072\n",
            "Epoch 47 | loss_tr 0.1194 acc_tr 0.9823 | loss_va 0.4374 acc_va 0.9087 | f1_va 0.9087\n",
            "Epoch 48 | loss_tr 0.1181 acc_tr 0.9825 | loss_va 0.4649 acc_va 0.9065 | f1_va 0.9065\n",
            "Epoch 49 | loss_tr 0.1173 acc_tr 0.9827 | loss_va 0.4698 acc_va 0.8936 | f1_va 0.8936\n",
            "Epoch 50 | loss_tr 0.1171 acc_tr 0.9829 | loss_va 0.4464 acc_va 0.8960 | f1_va 0.8960\n",
            "Epoch 51 | loss_tr 0.1170 acc_tr 0.9830 | loss_va 0.4731 acc_va 0.8961 | f1_va 0.8961\n",
            "Epoch 52 | loss_tr 0.1165 acc_tr 0.9830 | loss_va 0.4714 acc_va 0.9041 | f1_va 0.9041\n",
            "Epoch 53 | loss_tr 0.1164 acc_tr 0.9833 | loss_va 0.4462 acc_va 0.9034 | f1_va 0.9034\n",
            "Epoch 54 | loss_tr 0.1160 acc_tr 0.9836 | loss_va 0.4541 acc_va 0.9002 | f1_va 0.9002\n",
            "Epoch 55 | loss_tr 0.1154 acc_tr 0.9836 | loss_va 0.4103 acc_va 0.9062 | f1_va 0.9062\n",
            "Epoch 56 | loss_tr 0.1147 acc_tr 0.9840 | loss_va 0.4375 acc_va 0.9069 | f1_va 0.9069\n",
            "Epoch 57 | loss_tr 0.1150 acc_tr 0.9837 | loss_va 0.4626 acc_va 0.8981 | f1_va 0.8981\n",
            "Epoch 58 | loss_tr 0.1143 acc_tr 0.9841 | loss_va 0.4360 acc_va 0.9005 | f1_va 0.9005\n",
            "Epoch 59 | loss_tr 0.1136 acc_tr 0.9843 | loss_va 0.4531 acc_va 0.8997 | f1_va 0.8997\n",
            "Epoch 60 | loss_tr 0.1149 acc_tr 0.9839 | loss_va 0.4234 acc_va 0.9041 | f1_va 0.9041\n",
            "Epoch 61 | loss_tr 0.1138 acc_tr 0.9841 | loss_va 0.4458 acc_va 0.8974 | f1_va 0.8974\n",
            "Epoch 62 | loss_tr 0.1143 acc_tr 0.9843 | loss_va 0.4514 acc_va 0.9023 | f1_va 0.9023\n",
            "Early stopping — best F1: 0.9087\n",
            "Fold report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     no_pain     0.9399    0.9576    0.9487     13600\n",
            "    low_pain     0.7780    0.8762    0.8242      2400\n",
            "   high_pain     0.8321    0.5419    0.6563      1600\n",
            "\n",
            "    accuracy                         0.9087     17600\n",
            "   macro avg     0.8500    0.7919    0.8097     17600\n",
            "weighted avg     0.9081    0.9087    0.9051     17600\n",
            "\n",
            "\n",
            "OOF F1 micro: 0.9247\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     no_pain     0.9556    0.9631    0.9594     81760\n",
            "    low_pain     0.8700    0.8658    0.8679     15040\n",
            "   high_pain     0.7188    0.6730    0.6951      8960\n",
            "\n",
            "    accuracy                         0.9247    105760\n",
            "   macro avg     0.8481    0.8340    0.8408    105760\n",
            "weighted avg     0.9234    0.9247    0.9240    105760\n",
            "\n",
            "\n",
            " Metriche del miglior fold di validazione (micro):\n",
            "      Model  Accuracy  Precision  Recall  F1 Score - Val\n",
            "NN (fold 2)    0.9546     0.9546  0.9546          0.9546\n"
          ]
        }
      ],
      "source": [
        "X_all = data[feature_cols].values\n",
        "y_all = data[\"label_encoded\"].values\n",
        "sid_all = data[\"sample_index\"].values\n",
        "X_test_all = test_df[feature_cols].values\n",
        "sid_test_all = test_df[\"sample_index\"].values\n",
        "\n",
        "unique_sids = seq_df[\"sample_index\"].values\n",
        "sid_to_label = dict(zip(seq_df[\"sample_index\"].values, seq_df[\"label_encoded\"].values))\n",
        "y_seq = np.array([sid_to_label[s] for s in unique_sids])\n",
        "\n",
        "oof_probs = np.zeros((len(X_all), 3), dtype=np.float32)\n",
        "oof_preds = np.zeros(len(X_all), dtype=np.int64)\n",
        "oof_true  = y_all.copy()\n",
        "test_fold_probs = []\n",
        "val_metrics = []\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "skf = StratifiedKFold(n_splits=cfg.n_folds, shuffle=True, random_state=SEED)\n",
        "for fold, (tr_seq_idx, va_seq_idx) in enumerate(skf.split(unique_sids, y_seq), start=1):\n",
        "    tr_sids = unique_sids[tr_seq_idx]; va_sids = unique_sids[va_seq_idx]\n",
        "    tr_mask = np.isin(sid_all, tr_sids); va_mask = np.isin(sid_all, va_sids)\n",
        "    X_tr, y_tr = X_all[tr_mask], y_all[tr_mask]\n",
        "    X_va, y_va = X_all[va_mask], y_all[va_mask]\n",
        "\n",
        "    # Minority class oversampling is performed with SMOTE\n",
        "    class_counts = np.bincount(y_tr)\n",
        "    if len(class_counts) > 2:\n",
        "        majority_cls = int(np.argmax(class_counts))\n",
        "        minority_cls = 2  # high_pain\n",
        "        if class_counts[minority_cls] < class_counts[majority_cls]:\n",
        "            smote = SMOTE(sampling_strategy={minority_cls: int(class_counts[majority_cls])}, random_state=SEED)\n",
        "            X_tr, y_tr = smote.fit_resample(X_tr, y_tr)\n",
        "\n",
        "    mn, denom = fit_minmax(X_tr)\n",
        "    X_tr_s = apply_minmax(X_tr, mn, denom)\n",
        "    X_va_s = apply_minmax(X_va, mn, denom)\n",
        "    X_te_s = apply_minmax(X_test_all, mn, denom)\n",
        "\n",
        "    sampler = None\n",
        "    if cfg.use_weighted_sampler:\n",
        "        class_sample_count = np.array([np.sum(y_tr == t) for t in np.unique(y_tr)])\n",
        "        weight_per_class = 1.0 / np.maximum(class_sample_count, 1)\n",
        "        weights = np.array([weight_per_class[t] for t in y_tr])\n",
        "        sampler = WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n",
        "\n",
        "    classes = np.unique(y_tr)\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_tr)\n",
        "    full_w = np.ones(3, dtype=np.float32)\n",
        "    for i, c in enumerate(classes):\n",
        "        full_w[c] = class_weights[i]\n",
        "\n",
        "    # Spingiamo\n",
        "    full_w[2] *= 1.5\n",
        "\n",
        "    class_weights_t = torch.tensor(full_w, dtype=torch.float32, device=device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_t, label_smoothing=cfg.label_smoothing)\n",
        "\n",
        "    tr_loader = make_loader(X_tr_s, y_tr, batch_size=cfg.batch_size, shuffle=(sampler is None), sampler=sampler)\n",
        "    va_loader = make_loader(X_va_s, y_va, batch_size=cfg.batch_size, shuffle=False)\n",
        "    te_loader = make_loader(X_te_s, batch_size=cfg.batch_size, shuffle=False)\n",
        "\n",
        "    model = NeuralNetwork(in_dim=len(feature_cols), h1=cfg.hidden1, h2=cfg.hidden2, out_dim=3, dropout=cfg.dropout).to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    best_f1, best_state, no_improve = -1.0, None, 0\n",
        "    print(f\"\\n===== FOLD {fold}/{cfg.n_folds} — train rows: {len(X_tr)}, val rows: {len(X_va)} =====\")\n",
        "    for epoch in range(1, cfg.epochs+1):\n",
        "        loss_tr, acc_tr = train_one_epoch(model, tr_loader, optimizer, criterion, scaler=scaler, max_grad_norm=cfg.max_grad_norm)\n",
        "        loss_va, acc_va, preds_va, tgts_va = evaluate(model, va_loader, criterion=criterion)\n",
        "        from sklearn.metrics import f1_score\n",
        "        f1_va = f1_score(tgts_va, preds_va, average=\"micro\")\n",
        "        print(f\"Epoch {epoch:02d} | loss_tr {loss_tr:.4f} acc_tr {acc_tr:.4f} | loss_va {loss_va:.4f} acc_va {acc_va:.4f} | f1_va {f1_va:.4f}\")\n",
        "        if f1_va > best_f1:\n",
        "            best_f1 = f1_va\n",
        "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= cfg.patience:\n",
        "                print(f\"Early stopping — best F1: {best_f1:.4f}\")\n",
        "                break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
        "    # final evaluation on validation set with best_state\n",
        "    _, _, preds_va, tgts_va = evaluate(model, va_loader, criterion=None)\n",
        "    oof_preds[va_mask] = preds_va\n",
        "    va_probs = predict_proba(model, va_loader)\n",
        "    oof_probs[va_mask] = va_probs\n",
        "\n",
        "    # Report for each fold\n",
        "    rep = classification_report(\n",
        "        tgts_va,\n",
        "        preds_va,\n",
        "        target_names=[\"no_pain\",\"low_pain\",\"high_pain\"],\n",
        "        digits=4\n",
        "    )\n",
        "    print(\"Fold report:\\n\", rep)\n",
        "\n",
        "    # validation metrics for this fold\n",
        "    acc_va  = accuracy_score(tgts_va, preds_va)\n",
        "    prec_va = precision_score(tgts_va, preds_va, average=\"micro\")\n",
        "    rec_va  = recall_score(tgts_va, preds_va, average=\"micro\")\n",
        "    f1_va_macro = f1_score(tgts_va, preds_va, average=\"micro\")\n",
        "\n",
        "    val_metrics.append({\n",
        "        \"fold\": fold,\n",
        "        \"accuracy\": acc_va,\n",
        "        \"precision\": prec_va,\n",
        "        \"recall\": rec_va,\n",
        "        \"f1\": f1_va_macro,\n",
        "    })\n",
        "\n",
        "    # test prediction on this fold\n",
        "    test_probs = predict_proba(model, te_loader)\n",
        "    test_fold_probs.append(test_probs)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "oof_f1_micro = f1_score(oof_true, oof_preds, average=\"micro\")\n",
        "print(f\"\\nOOF F1 micro: {oof_f1_micro:.4f}\")\n",
        "print(classification_report(oof_true, oof_preds, target_names=[\"no_pain\",\"low_pain\",\"high_pain\"], digits=4))\n",
        "\n",
        "\n",
        "# we pick the fold with highest F1 micro\n",
        "best_fold_metrics = max(val_metrics, key=lambda d: d[\"f1\"])\n",
        "\n",
        "row = {\n",
        "    \"Model\": f\"NN (fold {best_fold_metrics['fold']})\",\n",
        "    \"Accuracy\": best_fold_metrics[\"accuracy\"],\n",
        "    \"Precision\": best_fold_metrics[\"precision\"],\n",
        "    \"Recall\": best_fold_metrics[\"recall\"],\n",
        "    \"F1 Score - Val\": best_fold_metrics[\"f1\"],\n",
        "}\n",
        "\n",
        "val_summary = pd.DataFrame([row])\n",
        "\n",
        "print(\"\\n Metriche del miglior fold di validazione (micro):\")\n",
        "print(val_summary.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Nt4ygz1LMXPX",
      "metadata": {
        "id": "Nt4ygz1LMXPX"
      },
      "source": [
        "## Ensembling → Predizioni Test + Aggregazione per soggetto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RuAydwlG4OGf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuAydwlG4OGf",
        "outputId": "d8095efc-15d4-4adc-8bca-182cef82a75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Post-processing OOF a livello sample_index ===\n",
            "Seq-level baseline (argmax) F1 micro: 0.9531\n",
            "➡️  Best F1 micro seq-level con soglia su high_pain: 0.9561 (t = 0.57)\n",
            "\n",
            "Seq-level classification report con soglia ottimizzata:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     no_pain     0.9639    0.9922    0.9778       511\n",
            "    low_pain     0.9158    0.9255    0.9206        94\n",
            "   high_pain     0.9500    0.6786    0.7917        56\n",
            "\n",
            "    accuracy                         0.9561       661\n",
            "   macro avg     0.9432    0.8654    0.8967       661\n",
            "weighted avg     0.9559    0.9561    0.9539       661\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================================================\n",
        "# 🔧 Post-processing OOF\n",
        "# ======================================================\n",
        "print(\"\\n=== Post-processing OOF a livello sample_index ===\")\n",
        "\n",
        "# aggregate by sample_index\n",
        "df_oof = pd.DataFrame({\n",
        "    \"sample_index\": sid_all,\n",
        "    \"y_true\": oof_true,\n",
        "    \"p0\": oof_probs[:, 0],\n",
        "    \"p1\": oof_probs[:, 1],\n",
        "    \"p2\": oof_probs[:, 2],\n",
        "})\n",
        "\n",
        "agg_oof = df_oof.groupby(\"sample_index\").agg({\n",
        "    \"y_true\": \"first\",\n",
        "    \"p0\": \"mean\",\n",
        "    \"p1\": \"mean\",\n",
        "    \"p2\": \"mean\",\n",
        "}).reset_index()\n",
        "\n",
        "y_true_seq = agg_oof[\"y_true\"].values\n",
        "p_seq = agg_oof[[\"p0\", \"p1\", \"p2\"]].values\n",
        "\n",
        "# argmax @ sample level\n",
        "baseline_preds = p_seq.argmax(axis=1)\n",
        "baseline_f1 = f1_score(y_true_seq, baseline_preds, average=\"micro\")\n",
        "print(f\"Seq-level baseline (argmax) F1 micro: {baseline_f1:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# - if argmax == 2 but p2 <= t -> assigns best between {0,1}\n",
        "# - else keep std argmax\n",
        "# ------------------------------------------------------\n",
        "best_t = None\n",
        "best_f1 = -1.0\n",
        "\n",
        "p2 = p_seq[:, 2]\n",
        "best_non2 = p_seq[:, :2].argmax(axis=1)  # 0 or 1\n",
        "\n",
        "for t in np.linspace(0.20, 0.80, 61):  # from 0.20 to 0.80 step 0.01\n",
        "    # argmax standard\n",
        "    preds = p_seq.argmax(axis=1)\n",
        "\n",
        "    # find high pain prediction with low confidence\n",
        "    mask_low_conf_2 = (preds == 2) & (p2 <= t)\n",
        "\n",
        "    # in this case, pick best between no pain or low pain\n",
        "    preds[mask_low_conf_2] = best_non2[mask_low_conf_2]\n",
        "\n",
        "    f1_micro = f1_score(y_true_seq, preds, average=\"micro\")\n",
        "\n",
        "    if f1_micro > best_f1:\n",
        "        best_f1 = f1_micro\n",
        "        best_t = t\n",
        "\n",
        "print(f\"➡️  Best F1 micro seq-level con soglia su high_pain: {best_f1:.4f} (t = {best_t:.2f})\")\n",
        "\n",
        "# final report\n",
        "final_preds = p_seq.argmax(axis=1)\n",
        "mask_low_conf_2 = (final_preds == 2) & (p2 <= best_t)\n",
        "final_preds[mask_low_conf_2] = best_non2[mask_low_conf_2]\n",
        "\n",
        "print(\"\\nSeq-level classification report con soglia ottimizzata:\")\n",
        "print(classification_report(\n",
        "    y_true_seq,\n",
        "    final_preds,\n",
        "    target_names=[\"no_pain\",\"low_pain\",\"high_pain\"],\n",
        "    digits=4\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_D7Gm-F4MXPX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "_D7Gm-F4MXPX",
        "outputId": "81b59ccd-2c66-49af-a6c9-b57a41aad5af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "no_pain      1040\n",
            "low_pain      183\n",
            "high_pain     101\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"agg\",\n  \"rows\": 1324,\n  \"fields\": [\n    {\n      \"column\": \"sample_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 382,\n        \"min\": 0,\n        \"max\": 1323,\n        \"num_unique_values\": 1324,\n        \"samples\": [\n          888,\n          756,\n          1164\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p0\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1324,\n        \"samples\": [\n          0.00863560102880001,\n          0.9045613408088684,\n          0.4249887466430664\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p1\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1324,\n        \"samples\": [\n          0.20699842274188995,\n          0.0688994750380516,\n          0.5273224711418152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p2\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1324,\n        \"samples\": [\n          0.7843660116195679,\n          0.026539215818047523,\n          0.04768877476453781\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_label_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"no_pain\",\n          \"low_pain\",\n          \"high_pain\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "agg"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-90fe8b8b-9e40-45cd-aef5-af1631986c69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>p0</th>\n",
              "      <th>p1</th>\n",
              "      <th>p2</th>\n",
              "      <th>pred_label_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.939205</td>\n",
              "      <td>0.051619</td>\n",
              "      <td>0.009176</td>\n",
              "      <td>0</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.981580</td>\n",
              "      <td>0.016512</td>\n",
              "      <td>0.001908</td>\n",
              "      <td>0</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.970753</td>\n",
              "      <td>0.016666</td>\n",
              "      <td>0.012581</td>\n",
              "      <td>0</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.885723</td>\n",
              "      <td>0.034470</td>\n",
              "      <td>0.079807</td>\n",
              "      <td>0</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.923291</td>\n",
              "      <td>0.016078</td>\n",
              "      <td>0.060631</td>\n",
              "      <td>0</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90fe8b8b-9e40-45cd-aef5-af1631986c69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90fe8b8b-9e40-45cd-aef5-af1631986c69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90fe8b8b-9e40-45cd-aef5-af1631986c69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7e1963c3-c518-458b-9a51-18a9c8670267\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e1963c3-c518-458b-9a51-18a9c8670267')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7e1963c3-c518-458b-9a51-18a9c8670267 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   sample_index        p0        p1        p2  pred_label_id    label\n",
              "0             0  0.939205  0.051619  0.009176              0  no_pain\n",
              "1             1  0.981580  0.016512  0.001908              0  no_pain\n",
              "2             2  0.970753  0.016666  0.012581              0  no_pain\n",
              "3             3  0.885723  0.034470  0.079807              0  no_pain\n",
              "4             4  0.923291  0.016078  0.060631              0  no_pain"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_mean_probs = np.mean(np.stack(test_fold_probs, axis=0), axis=0)\n",
        "df_test_pred = pd.DataFrame({\n",
        "    \"sample_index\": sid_test_all,\n",
        "    \"p0\": test_mean_probs[:,0],\n",
        "    \"p1\": test_mean_probs[:,1],\n",
        "    \"p2\": test_mean_probs[:,2],\n",
        "})\n",
        "agg = df_test_pred.groupby(\"sample_index\")[[\"p0\",\"p1\",\"p2\"]].mean().reset_index()\n",
        "agg[\"pred_label_id\"] = agg[[\"p0\",\"p1\",\"p2\"]].values.argmax(axis=1)\n",
        "inv_label_encoder = {0:\"no_pain\", 1:\"low_pain\", 2:\"high_pain\"}\n",
        "agg[\"label\"] = agg[\"pred_label_id\"].map(inv_label_encoder)\n",
        "print(agg[\"label\"].value_counts())\n",
        "agg.head()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QUO4aF9rMXPX",
      "metadata": {
        "id": "QUO4aF9rMXPX"
      },
      "source": [
        "## Salvataggio `submission.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oSltkmYZMXPX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "oSltkmYZMXPX",
        "outputId": "1dbf3702-d392-42af-9e86-6eae0cb2fdae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✔️ Salvato: /gdrive/MyDrive/DeepLearningChallenge/submission.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"submission\",\n  \"rows\": 1324,\n  \"fields\": [\n    {\n      \"column\": \"sample_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 382,\n        \"min\": 0,\n        \"max\": 1323,\n        \"num_unique_values\": 1324,\n        \"samples\": [\n          888,\n          756,\n          1164\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"no_pain\",\n          \"low_pain\",\n          \"high_pain\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "submission"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-70909645-d915-4c28-8576-125f49ba2d95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70909645-d915-4c28-8576-125f49ba2d95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70909645-d915-4c28-8576-125f49ba2d95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70909645-d915-4c28-8576-125f49ba2d95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e3c9923f-2116-4b55-910b-e0395518ced0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3c9923f-2116-4b55-910b-e0395518ced0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e3c9923f-2116-4b55-910b-e0395518ced0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   sample_index    label\n",
              "0             0  no_pain\n",
              "1             1  no_pain\n",
              "2             2  no_pain\n",
              "3             3  no_pain\n",
              "4             4  no_pain"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission = agg[[\"sample_index\",\"label\"]].sort_values(\"sample_index\").reset_index(drop=True)\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"✔️ Salvato:\", os.path.abspath(\"submission.csv\"))\n",
        "submission.head()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
